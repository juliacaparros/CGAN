{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8059eb1f",
   "metadata": {
    "id": "8059eb1f"
   },
   "source": [
    "## LINMA2472 - Algorithms in Data Science\n",
    "# Homework 1: GAN (in fact CGAN)\n",
    "\n",
    "Bastien Massion - bastien.massion@uclouvain.be\n",
    "\n",
    "06 October 2024 - v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfcb6a-ecd9-446a-bb31-5efb7d644de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa4f162",
   "metadata": {
    "id": "efa4f162"
   },
   "source": [
    "## Guidelines\n",
    "This homework is done in Python, using the PyTorch library for neural networks.\n",
    "\n",
    "The homework is divided in 2 sections: training a CGAN and explorizing the latent space.\n",
    "This Notebook contains codes to be filled-in. The goal of the homework is to use a GAN for generating handwritten numbers (and letters).\n",
    "    \n",
    "A big part of the code for training your CGAN is already given in this Notebook. Every part that you will have to complete is indicated in the title by a mention. When it implies to write some code, the precise location is mentioned by the line `# TO COMPLETE`. The existing code should be sufficient, but can be modified at will if it turns out to be useful for you.\n",
    "\n",
    "Note that the proposed code gives sometimes unnecessary options for the asked tasks, but this is on purpose: this code could become an inspiration/foundation for any future CGAN project that you may have. The overlay should make the code clearer, more robust and generalisable to other possible datasets (eventually your own dataset) or tasks to offer you a better PyTorch GAN framework. Every time additional parameters should not be changed, they will be indicated by the line `# DON'T MODIFY`.\n",
    "\n",
    "The project is done by groups of 3. Once the group is formed, register it as soon as possible in the Moodle activity \"Group choice for Homework 1\".\n",
    "\n",
    "The deadline for the whole homework is: **Monday 21 October 2024, 23:59, on Moodle**.\n",
    "    \n",
    "Using AI writing/coding assistant (such as Chat GPT) is allowed, but you absolutely have to detail where you use it, which prompts were given and what answers you received.\n",
    "\n",
    "Your questions or comments should be posted on the dedicated Moodle \"Class forum\" or kept for the Q&A session that will take place on: **Monday 7 October 2024, 08:30, in BARB91**. As a last resort, you can send them directly to the mail address: `bastien.massion@uclouvain.be`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbdaa9",
   "metadata": {
    "id": "2dcbdaa9"
   },
   "source": [
    "## Introduction\n",
    "Since their introduction in 2014 by Goodfellow et al., Generative Adversarial Networks (GAN) have taken a predominant place in the deep learning landscape. GANs are deep neural networks composed of two parts: a generator and a discriminator. Those two parts are trained as opponents (hence \"adversarial\"): from the dataset, the generator tries to create new fake data that can fool the discriminator into thinking they are real, while the discriminator tries to distinguish between true and fake data.\n",
    "\n",
    "Often, the most interesting part of this model is the generator, therefore we often refer to GANs as generative models. Together with diffusion models (such as Stable Diffusion or DALLE-3) for vision and with transformer models (such as GPT4) for language, these generative neural networks make up a large part of the AI world today. Experts think that we are currently living in the era of Generative AI. Lectures about some of those other topics are coming soon!\n",
    "\n",
    "These generative properties are used in a lot of applications: mainly for image processing tasks (style transfer, segmentation, face generation, image inpainting, deblurring, super-resolution,...), but also for natural language processing tasks (text summarization, text generation,...), for music generation or even for medical tasks (tumor detection). Another major use of GANs is data augmentation, which can be successful in any data-driven sector for which collecting large annotated datasets is costly or risky (medicine, biology, psychology,...). Of course, new applications emerge and perspectives unimaginable a few years ago could soon become reality.\n",
    "\n",
    "Conditional GAN (CGAN), introduced in 2014 by Mirza and Osindero, is a variation of the classical GAN architecture that aims to give more information to the networks to improve and control the generated outputs. In particular, the generator and the discriminator both receive the class that should be generated or discriminated.\n",
    "\n",
    "The goal of this homework is to implement your first CGAN and explore some properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e1e84",
   "metadata": {
    "id": "070e1e84"
   },
   "source": [
    "## Packages import\n",
    "You will need several packages in order to successfully build, train and use your neural networks. In particular, we use the PyTorch framework and some of its extensions (`torchvision` and `torchinfo`) to work with neural networks.\n",
    "\n",
    "Normally, all packages except `torchinfo` should be installed by default. However, it could be possible that some of those packages are not installed yet on the hardware you will be using for this homework. Please install them properly by following the installation guidelines in their respective documentation. If they are already installed, don't hesitate to update the packages to their most recent versions: it will run faster and safer.\n",
    "\n",
    "The code below will automatically download the `torchinfo` package if it was not done already.\n",
    "\n",
    "The following packages are necessary and should not be removed. However, if you want to add other packages for your figures, for timing or whatever, feel free to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0852bb",
   "metadata": {
    "id": "4a0852bb"
   },
   "source": [
    "## Resources\n",
    "Training a neural network is really expensive, especially if your network is large. Moreover, training GANs is famous for its instability, as you might figure out. It is thus important to look for the most suited computing and storing resources.\n",
    "\n",
    "In practice, parallelisation of computations can speed up the process a lot, by several orders of magnitude. In particular, computing on a GPU (Graphics Processing Unit), which has up to hundreds of cores, will be much faster than on your usual laptop CPU (Central Processing Unit), typically with less than 8 cores.\n",
    "\n",
    "Therefore, it is useful to search for the maximum available computing power.\n",
    "\n",
    "In this project, you are encouraged to use (external) GPU solutions. Indeed, staying on your own CPU laptop could take up to several hours for one training session... Here are some solutions to acquire such GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee998b0d",
   "metadata": {
    "id": "ee998b0d"
   },
   "source": [
    "### Your own power\n",
    "If you have the chance to have your own GPU (as a gamer for example), then please use it!\n",
    "\n",
    "The use of the CPU of your computer should be problematic for the training process of GAN, but not for the inference part. Typically, if you just want to create new images from your trained model, your CPU should be sufficient. So, the second part of the project should be doable on your CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5abf9f",
   "metadata": {
    "id": "6b5abf9f"
   },
   "source": [
    "### External power: Google Colab (free)\n",
    "\n",
    "To access more computing power, we ask you to use Google Colab: https://colab.research.google.com/.\n",
    "\n",
    "Colab is a free and easy to use service from Google, where you can borrow their efficient resources. You only require one Google account, i.e. one Gmail adress, to use Colab and run code online.\n",
    "\n",
    "The most common and easiest way of using Google Colab is to work with a Jupyter Notebook, so this one will perfectly do the job! Launch Colab, in files \"import a new notebook\" and select your Notebook for this homework. The Notebook is stored on the Google Drive associated the Gmail address, while all the related files (data, generated figures, saved models, saved latent vectors) exist in folders on the computing unit that you are connected to, and are stored in the same directory as your Notebook.\n",
    "\n",
    "As a first step with Colab, you can use the free option. In this setting, you often have access to nice GPU's: Nvidia T4 GPU. Be aware, GPU are sometimes not available (reserved in priority for people with paying subscriptions) and there are limitations to the amount of computations that you can do in one go with the free setup (\"usage limits\"), so don't hesitate to start this project as quickly as possible. The whole project is doable on these T4 GPU's: it is our recommended option to make this project.\n",
    "\n",
    "To select your resource, click on the triangle next to \"Connect\" in the up-right corner of your screen (see image) -> \"Change runtime type\" -> Select your \"Hardware accelerator\" -> \"Save\". It should then become \"Connected\" to the hardware you chose.\n",
    "\n",
    "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAYgAAAB+CAIAAACxnRHBAAAW6ElEQVR4Ae2df1AUV4LH3dTeXf5a77au6mq38k9nU3tjSJUXYkysVLxUI1WoOMZAYjJVqYCbsyAhmohoTCi1hCkv4KUGpYKgJC4aBbnjQBMBl4RdtRpSCiaAt5ExGzEmmPEH8xNmYJi+6u6Z5jE/e2a6m8b5dk1JT/fr9+PzXn/mvddvxgUsNhAAARDQGIEFGssPsgMCIAACLMSERgACIKA5AhCT5qoEGQIBEICY0AZAAAQ0RwBi0lyVIEMgAAIQE9oACICA5ghATJqrEmQIBEAAYkIbAAEQ0BwBiElzVYIMgQAIQExoAyAAApojADFprkqQIRAAAYgJbQAEQEBzBCAmzVUJMgQCIAAxoQ2AAAhojgDEpLkqQYZAAAQgJrQBEAABzRGAmDRXJcgQCIAAxIQ2AAKpS2Dq2jl3R5mzdq29fJG1ZOHYWw+MvfWAtWShvXyRs3atu6Ns6tq5OaEDMc0JdiQKAnNJYNpiHm/dZit9aKxoQcyXrfSh8dZt0xazmjmGmNSkjbRAYI4J+Oy3XI2FMWUUNoCrsdBnv6VOASAmdTgjFRCYewIe5jA3XpPQS4oUxlqy0MMcVqEkEJMKkJEECMw9gYQ7SqGScjUWKl0eiElpwogfBOaegLN2bahfkjnirF2raKkgJkXxInIQmHsCsltJMJqiboKY5r7dIAcgoBwBGUdwoT0s5cZ0EJNyTQIxg8AcE/Awh0NtIu8RhebCIaY5bjpIHgQUIuCz30ryGZwUhVlLFiqxhkBBMfX09Dz//PNU/NvatWv7+voUqi1ECwIqE7Db7WvWrKEDm16vdzgcKuRB0UEc6SwlBnQKikmv18cvJf8Vr7zyigo1hyRAQAUCAwMDASn5/w4ODiqd7rTFTLpD6X3Z14UrKKYlS5YkLKZly5YpXXOIHwTUIXDmzJkgMXV0dCid9HjrNkky2vRL255/tZWn+V9li2zv/Wbs7X+QdC2xUHO8dZu8JVJQTOnp6QmLaenSpfKWE7ElRuDnn3/evXv3hg0b6urqvF6vGInX662trd2wYcOePXssFot4XK4dS3M+ReU3jcoVn6rxtLW1VVZWCt2iq1evFhQUBImpsLDw2rVrLMsODg5WVlaePn1a9vxJ/B6cdeuvxk+/P3H2A/+r0zj+3287D+c4TP9uK9ONvf3gWNEvpEjKVvqQvEVQUExkj6m+vr4n1lZfXy+K7Omnn46vnLahtr0F2ct0XAzpmYbSpiFbfBEgdCiB0dHRxx9/XKyUN998UwyTn58vHl+yZMnt27fFU3HsWJhDWwyZwudXembB3jax1uavmCwWy8qVKwUTGQyGICWRb8WzK1euTBBgBNZT185JsclY0QLb+7+dtv7I+ry+yQnfhJ17uR0+15j3pyF3t4lz0+a/kxiVvL9DoKCYyB5TT09PBIYzh3t6esS2Hl+P6Ye2gnSKSjfsPNbGnGe6m42GdIpKy2/6YSby+bZnaeJ7DPJ3ReIB8d5774k1IuwIDyXOnz8fdLysrCyeiPmwPzTlp1G61Zv3NXfP1Fp6QRvfS5q/Ytq1axdpH4n7e/bsiRtg5AvcHWUSbSKIyWe/NTX0mburwv3FPs+Fg1Pmv0xbb07fu+Hp+di67dcSo3J3xN8GIhdBQTGRPaZVq1a9HGtbtWqV2Nzj6THx9/CzRobsIrm6d6ZRuk0d5LHIEDR4RhNievXVV8UaEXaam5tZlj1+/HjQ8fz8/DghupndOiptZ7eLuE6otd2Mm2XnqZguXboUyURr1qwpLCwkH88Fhfz6668JFkntSl/qLYhp+u71ic9KbXt+b9vze3v5o459T3vOf+Rz3vaOXLLt+BeJYpJ3IbiCYnriiSfE5rt161ZTrG3r1q1i+KeeekpqzVypXk5RBaeCFTS0fzlFbQ6YyW0+ZSxYsZiLPz2zYD9jEWdLLhopijJ2mZtKc5amURS1OLPgUJ+NZS1MdUEmd0Ha0pzSJrP//vH7oo+pFmLTLcvZeeoGy7rNzTtz+IHk4hUF1QzR0fHahsKeEtJlLMz+An4so1v6uv+6vr0iBm4nv5mITSoUecKZTCYyKw8//PD333/PsuzVq1fJ4xRFHTx4MM4kw5rXzVRkZ794aEgU09WZeiFqgUvKdqXNKFQQV2UEcn+FDh16famOoowX+XxFqoU4Mx0z+NGjR4N0Q9P0qlWrOjs7xWs7OzuzsrJCg3366adimCR37OWLJNrEL6Y7f3M1FpCXjP/POz7brWmLmZsLJya5o+zbyxclmW3ycgXFpM5Qjv9oNYQZtblttns2Nycgd9+HmRS12LDfP9DLSaN0rzfdENzEt2Nd2lLhbFttQSZFUS/k5KRlFtRy4YUjy/f2uTls/O2Uplu8entDF8N0NRlf1FHU8pwXM3UvGptmjoiztu6+vZlUWo6RH620fZijo3SbP+cdyqebuSI7e0dDNz/8zEnjZns5CblstntDDQaKMjQM3bPZ+ITJOlNtf2JiYt26daKDPv74YzHpAwcOiMdffvnlyclJ8ZS0Hb7HROVUD4QvHl+tyzNXzKqXQC2w7ovGTEonoGO6GravoKgV+4QaYv0Vunjp6zv3fbiv4zrfACLVgrS8Sg/l8/mOHDmSkZFBeqelpSUohuPHj5MBMjIyGhoagsIk81b6usoQMf1i7O0Hbbt/5+6q9Fl/iqvHZC1ZmEyeg65VUEzq9Jj4/oUogqDS8W+vN+RQVP6JG+I5vlkHOll8OybPmuuzuX7KTHh3dylFpe3jV3zyYnrWyIgDEFf3doqiyCPXGrIpKr+FM4z7onE5tdzIDU2Ezd1dqqOerR5iWeH+yfT7jjtrPsJd1+bvHoXtUASiUfGv1+ttb2+vq6sLXXpz+fLlurq6zs5O8mldHFlz9RlXcF3UnC2H2gZu8B8hM1fzYtLlN4u1NqsWOkqzs7cEULEsO8D1mnd285wF4xNgo9XCTIJy7rW2toreycjI8Hg8QbG7XC4xAE3Tsj+V434hV1o3xy+meyPjbdtt7//GVvqQ7T//baK9zPvD5el7I57zB63b/kliVGNvPRBUzGTe3v9i4m94cUwnsDI36ClKmIHi27G/w8+fDO2C8UeMM2IS+jV+6n3cULCMIeqAOyKMv/r2BjQUOG37fLP/KXhIuizDXRd4QK4VMQUyrsxfr4Wp3ZzjX1XCGUocBPPMRRpc6jdOGChKqIWQzIzyjwqEMW8I2Gi1EBKTLAcuXLggeuell14KG2dubq4YRsqjobCRRDoYr5hY76TPeXf67sj0vZFp60++Ceu09UdP7x9tu343tumX95uY1BnKxewx8QGCGzR3kOi5hIhp1i0RW0x7yS/QiGLi5SIOeGZ2+MhD7h++DyWmqwkx/fjjj2fPnq2qqjKZTHV1dT09PePj4+LN4HQ6Dxw4UFVV1dHRMTqa1Ioj9/W+pg83Z6dRVFrOoStcxydUTEQtcFmwnD+0+VV+EjAA1j8ZFww2ai2IhZF1h+wx0TQ9MTERFL3SPaZ4h3K+8THvza+n/q+De/2103v9q+k733t/Gpr40wfWkn+UKCYM5WbVMt9eo80xhRUTU6aWmPTGtvMMM+vVd8PtH8qRQtSOmKamppqamsiHpIF7n3rkkUc2bdo0NMQNRlmWPXv2rHhqzZo1LS0tCQ7rhOhsjPFZ/0RbdDGZjxl0VOb2Y4x5lJtJtF3hZuSiiSlSLQjpyvdv2Dmmw4eDf4u2pqZG7C7RNC37HFPck99jN91/PuA8uMZZq3fW6l2fvOK5UDttGfbe+qvzcI51+z9LcdO8nPwWm6/EnTjWMcV6KpfQUE7suXBtlvisDu3I8EO58D0mflrk2eoh8QkgeQMEf7ALqhLTDU2IvFjB/YGBgWeeeSZmNRUXFwsOeuONN8jAzz333HfffRc7f9ca8vXZ2z8PfuAofopEFVPfvjRKRzKPNpSLWguxMxpfiCNHjpDGEfcrKiqEJZQWi8VoNIrHyZ2jR4/Gl1jk0HEvFwh5Kuc8tG7q6pc+j9PDHLYbH5MipnmzXODJJ58km2xc+4msYxInpLkHW8Q6JgmT32TPJeotEeqLKGJibR3bucdwp4jbzzXE9M88lSPT1UiPafXq1RJr6sSJEyzLNjY2BoU3GAyRb5nAGXef0DnyPxsVDnvNDS9QlL7BHGMoxzMn5vXcjHF5xB5T1FoIZEeuv/39/aRryP2MjIwNGzaQR4L2ZVzHFO8Cy+kQMTkOrJjsb/ZNjk8OfWaveEKKmObNAkvyWwtBbTfm2zjWMbEsy68hptINwlN5/8rv9II2/8rv2MsFSEHIKCbWe6PpdR1F+VceMKcOFazgVyrEHsoJ6w/zq7sY5mrwEi257qKw8aSlcau5pGw7duxgWfbLL78MCvzYY4+FjTnooPvivmxi5TdzqmHnq4spKtN4MeYck7DUYLFhb1P3+baGUgO/Pi3SUI6NVgtBeZLjrRZWfsf7lZRQMTkP50yZ/+LzuCYvnbDvXSxFTPPmKykjIyN5eXmx1nvPnCeXzMTTY+JbE/9dOeFbV7pl2eS3rvjTsRZYCsvw+KByiollWeHBE7/2UrcsZ3NtYG1njKEcy/7QsfMF7o5bvJ+cWZfj1okax6JFi4JEE+ltSUlJWDE9+uijUVMgTo72NYnfcExbml1gbLvit3DUWuCp7s8PLIitZka5J5r+Z6OhYKPUApEXuXYtFou4flL8NlxQ50h4K55duXLlnTt35MqAEI/EL/H6lwtwz+COuI7/h+v4RldjwcSp9yYH2ny20emxm67jG23v/zammObTl3gTAP3BBx8It0Ecc0wJJINLIhN47bXXZj4rou4Jq70vX74cFCovLy9y9Clxhvx1geHh4bC/LmA2c/+x7eDgYEVFhezrmFiWlfizJ4KYfG7HtMU89X0v97r+lffmN9M/D3tv9LvPVdvKHx1758GYYppPP3uSWBssKyujKApiSowertIggTn5PSaJPxRn3fZrT++RycFTM6+Btsn+k54LteP/u9Ve+eTY5r+PaaWxogXz6YfiEm4ipaWlEFPC9HCh1gh88803QUM5cb2FolnFT+vKj7e6ulr+SBEjCMwFAbvdnp2dLbpJr9c7nU4VMoL/jEAFyEgCBEAgbgL475viRoYLQAAEVCCg6IBOif8fRWCi4Jd4VYCOJEAABGISkL4QXMo8txhG3qXeQaWAmIKA4C0I3IcEZHeTolZiWRZiug9bIYoEAqEEZBzTKTeCE7MNMYkosAMC9zkBD3NY+i+iiEM2csdastDDBP9YghLUICYlqCJOENAoAZ/9VsJdJ1djoc9+S52CQUzqcEYqIKAhAtMW83jrNqnfpyt9aLx1m+xru6PjgJii88FZELifCUxdO+fuKHPWrrWXL+JGeW89MPbWA9aShfbyRc7ate6OMnl/M0A6SohJOiuEBAEQUIkAxKQSaCQDAiAgnQDEJJ0VQoIACKhEAGJSCTSSAQEQkE4AYpLOCiFBAARUIgAxqQQayYAACEgnADFJZ4WQIAACKhGAmFQCjWRAAASkE4CYpLNCSBAAAZUIQEwqgUYyIAAC0glATNJZISQIgIBKBCAmlUAjGRAAAekEICbprBASBEBAJQIQk0qgkQwIgIB0AhCTdFYICQIgoBIBiEkl0EgGBEBAOgGISTorhAQBEFCJAMSkEmgkAwIgIJ0AxCSdFUKCAAioRABiUgk0kgEBEJBOYMEwNhAAARDQGAH0mKRLHCFBAARUIgAxqQQayYAACEgnADFJZ4WQIAACKhGAmFQCjWRAAASkE4CYpLNCSBAAAZUIQEwqgUYyIAAC0glATNJZISQIgIBKBCAmlUAjGRBQn8Dw8LD6icqSIsQkC0ZEAgJaJAAxabFWkCcQSHECEFOKNwAUHwS0SABi0mKtIE8gkOIEIKYUbwAoPghokQDEpMVaQZ5AIMUJQEwp3gBQfBDQIgGISYu1gjypRmCUqd9RmJtF0zSdpTcU1zCjqiWNhKIQgJiiwMGp+5uAo/+AIYvOMrxb0/pFby9zpv5dQxZN55r6Hdos92hrEU0XtaSEOiEmbbZB5EpxAp5LVXqaLmocIVMaacij6dyaK+QxzewnIqb+Kq4zOGurukSU6BJ/3tRPHNLErrxiauU3dQqGld/qcL5fU3F0vUvT62queGcX8O6ZYprW1wbM5L3b+8mOvHXcUC9rXZ6xxewIhB9t4bovrd+aW8vz9Pz5vPJWs7+vxevA1Hv3q5pifpiYta6o5qu7ZEqjjHiKj5Y45/i21fgHIUp93vvH+q0sywb5pag1zm4Tl9swF/VX0UVVpiL6vhZTe3t7Pr+1t7cTmJXahZiUIpsa8fK3ekVvaGE9VodjXDg82rqJG+rtauzqZXrPfFKcSwz0eDHpc9frN350RjyrN/V7uEv5yNfnGgy7Tn7R2/tFa+XGLM5iAZuMthRl0bnFn3AXdjXu4qINqNBxqYp7u/NkF9Pb+8XJXetpen1Vv4PlcvXtsY00vfFTs8Pq8AT8GJr/sEfCiqnfRNOmfu5UomIymUxVkTeTyRQ2M1IOytVjEq2kmpsgJin1izARCPDDoug3pOe8MYvWV341M+PEC0VfM8jFyYspi5jx8Zwrp+msKn5QJIiJE4p/+9sxA00XtfGdJmFE1hywFMvy48cdXVzPaOTkH0iDsSzfg/OnkshQzp9+GDFxgzgut8mIiWVZk8k0a6AYeJOMlViWlUVMp0+fFny0ld+E/dOnTwdqRZG/EJMiWFMl0thi4kWzbvZ00/g5Y2Cgx4tpphPEqap5o3Cr+3tMZDfE21sZmLfmLxQ0FIB9pUZP09zUD++vHWdFn7Es6xm93NtrJoyW0OR3iJi48guTTUmKKaybkrSSLGIS+0pbtmy5c+fO7du3t2zZokK/CWIKNGv8TYBAbDEJ/RNx+CWkwR98t8vh7zHNFhM360T0mEgx8YM7oePDDaDCbZwm+KnoWZPTZNGEHMkhJlJG5D6ZWlz7ZL8peSslL6YgKwllUcdNEFNcLQeBgwjEnGMKL6aTG2laBjEVH2N6e2e/uF6RSmLiixYsx1mSDYIl5a3gJlmslKSYwlpJKIIKboKYpLQWhIlEIOZTufiHctJ6TCMNBpouPjPrGV0gkzc57xn/zE+gB455HIHJePl6TIG4ub+y9JiECOWyUjJiGh4eFsZr77zzzu3bt8mSCvukm8xmc2iAJI9ATEkCTPXL/euYiElobvKZWMckYfJ7Vi+Du8MlDOXYb+u5524fBVYksCzrHe1lhOVU5vr1NF1CWMtxzphF5wmLrTQvJhmbVDKT301NTcK8UqT8CG5SaPUAxBQJO45LJODoN+XS3Mrv+jPcqEpY+Z1lOCA+TIu5XCAhMbH+dDdWtPJrAvjFBOsre7mncmzwcgFDlrBcgDs3zkkqa1N9F+OfDZdYzvkYLBkxcRgd5AOEMABcLleYo3IcgpjkoJjycXDflRNWM9JZuYU76oO+KxdzgeXMQ39hAUHsyW8eucPcXimsvaRX5xb/1xkzbyWhNmYtsCxvJU+NnjXmreYWewpLFu7j2ktSTHNIBmKaQ/hIGgSUJQAxKcsXsYMACCRAAGJKABouAQEQUJYAxKQsX8QOAiCQAAGIKQFouAQEQEBZAhCTsnwROwiAQAIEIKYEoOESEAABZQlATMryRewgAAIJEICYEoCGS0AABJQlADEpyxexgwAIpBQBrPxOqepGYUFgfhCAmOZHPSGXIJBSBCCmlKpuFBYE5gcBiGl+1BNyCQIpRQBiSqnqRmFBYH4QgJjmRz0hlyCQUgQWDGMDARAAAY0RQI8ppT6HUFgQ0AqB/qgbxKSVekI+QCClCPT395vN5usRtv8H3rzAyJ2khSAAAAAASUVORK5CYII=)\n",
    "![image.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9590542",
   "metadata": {
    "id": "a9590542"
   },
   "source": [
    "### External power: Google Colab (paying option)\n",
    "However, we allow you to buy premium resource (click on \"Purchase additional compute units\"). In particular, we will refund one \"Pay As You Go\" subscription per group. It costs 11,19€ for 100 compute units, valid for 90 days. Note that you need a credit card to buy it.\n",
    "\n",
    "For the refund procedure, you need to keep a proof of payment to Google Colab. After the deadline of this homework, an Excel file will be posted on Moodle and you will have to fill in with your refund information. Finally, you will send the Excel file and the proof of payment in one mail to Bastien Massion (bastien.massion@uclouvain.be), as soon as possible. The refund demand will then be treated.\n",
    "\n",
    "With such compute units, you can get guaranteed access to Nvidia V100 GPU's, which work a bit better than T4 ones. If you're lucky, you could even have access to Nvidia A100 GPU's, which are amongst the best GPU's on the market.\n",
    "\n",
    "100 compute units should allow more than 5 hours of computing. You can check your remaining total on: triangle next to \"Connect\" -> \"View resources\". However, be aware that when you possess the paying option, running with T4 GPU's will also cost you compute units...\n",
    "\n",
    "If, despite all of this, you are not satisfied, feel free to contact Bastien Massion by mail."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f24149",
   "metadata": {
    "id": "05f24149"
   },
   "source": [
    "### What is available?\n",
    "The function `chooseDevice` automatically checks two things. First, it checks whether the run is done on Colab or on you own computer. If you are using Colab, then the source is set up as the Google Drive you are working with. Colab should ask your permission to access your Google Drive and be able to interact with it, accept it.\n",
    "\n",
    "The second thing this function does is to check if there is a GPU available. If there is one, computations will be done there using CUDA, a parallel computing package and programming model created by NVIDIA. The code `.to(device)` is necessary to work with the GPU. It is already added where it should be, but simply be careful of adding everywhere it will be needed if you modify the rest of the code or for your further analyses. Otherwise, computations will be done by default on CPU.\n",
    "\n",
    "The `num_workers` parameter is a bit obscure, but it roughly indicates how many units you would like to use for downloading data. It seems that 2 is fine for Colab GPU, 0 is fine for your own GPU and 0 is fine for any CPU.\n",
    "\n",
    "There should be no need to modify the function `chooseDevice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2376a",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1727106015869,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "aea2376a"
   },
   "outputs": [],
   "source": [
    "##### Check if GPU is available\n",
    "\n",
    "def chooseDevice():\n",
    "    try:\n",
    "        import google.colab\n",
    "        machine = \"colab\"\n",
    "        print(\"Working on Colab\")\n",
    "\n",
    "        from google.colab import drive\n",
    "        source = \"/content/drive/MyDrive/Colab Notebooks\"\n",
    "        drive.mount(\"/content/drive\")\n",
    "        print(\"Connected to Google Drive\")\n",
    "    except:\n",
    "        machine = \"own\"\n",
    "        source = \".\"\n",
    "        print(\"Working on your own computer\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"GPU available via cuda\")\n",
    "        if machine == \"colab\":\n",
    "            num_workers = 2\n",
    "        elif machine == \"own\":\n",
    "            num_workers = 0\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        num_workers = 0\n",
    "        print(\"GPU not available, CPU available\")\n",
    "    print(\"Number of workers:\", num_workers)\n",
    "    return machine, source, device, num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ee1e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17389,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "f68ee1e2",
    "outputId": "4e7ee3b7-1930-43be-83c8-e6975e2bd93b"
   },
   "outputs": [],
   "source": [
    "machine, source, device, num_workers = chooseDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c5e3d",
   "metadata": {
    "id": "180c5e3d"
   },
   "source": [
    "## Files management\n",
    "During this project, you will create and store new files, in particular model states, figures and latent vectors. To manage it correctly and avoid errors, we create folders to host these files before running the rest of the code.\n",
    "\n",
    "If the source is Google Drive, then everything will be stored there: make sure that you still have room left on your drive! If the source is `'.'`, then it will be stored on your computer memory next to this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08fc0b-90bd-475b-8ccc-361e1f83043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f994f03c",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "f994f03c"
   },
   "outputs": [],
   "source": [
    "def createFolders(source):\n",
    "    if not os.path.exists(source + '/Data'):\n",
    "        os.makedirs(source + '/Data')\n",
    "    if not os.path.exists(source + '/Models'):\n",
    "        os.makedirs(source + '/Models')\n",
    "    if not os.path.exists(source + '/Figures'):\n",
    "        os.makedirs(source + '/Figures')\n",
    "    print(\"Folders created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e65cc95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "4e65cc95",
    "outputId": "d6871420-0b28-456f-ab63-4a76717c593a"
   },
   "outputs": [],
   "source": [
    "createFolders(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37aedbd6",
   "metadata": {
    "id": "37aedbd6"
   },
   "source": [
    "## Set random seed\n",
    "Setting the seed for the generation of random numbers is not necessary, but can be useful for keeping consistency in your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd917227",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "fd917227"
   },
   "outputs": [],
   "source": [
    "seed = torch.manual_seed(2472) # DON'T MODIFY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31ba9e",
   "metadata": {
    "id": "2c31ba9e"
   },
   "source": [
    "## Datasets\n",
    "Three datasets are proposed, all part of the EMNIST (Extended MNIST) dataset.\n",
    "\n",
    "First, the **EMNIST Mnist** set, i.e. the classical MNIST set, which should only be used as proof of concept. It contains a total of 70 000 handwritten digits (60 000 train, 10 000 test) from 10 balanced classes (one for each digit).\n",
    "\n",
    "Then, the **EMNIST Letters** set. This second dataset is larger (more data and more classes), which create more impressive results. It contains a total of 145 600 handwritten letters (124 800 train, 20 800 test) from 26 balanced classes (one for each latin letter, lowercase and uppercase mixed). It is optional, but could be used to create more impressive results.\n",
    "\n",
    "Finally, the **EMNIST Balanced** set. This third dataset is a bit smaller but has more classes: 131 600 handwritten letters or digits (112 800 train, 18 800 test) from 47 classes (some uppercase and lowercase letters are split, some are not, and the digits). It is optional, but could be used to create more impressive results.\n",
    "\n",
    "Every image is originally of dimension 1x28x28, which means that there is only 1 color/channel (greyscale) and that it has size 28x28 pixels (height, width).\n",
    "\n",
    "More info on the EMNIST Dataset can be found here: https://www.kaggle.com/datasets/crawford/emnist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c23cd",
   "metadata": {
    "id": "258c23cd"
   },
   "source": [
    "### *EMNISTDataset*, *SwapAxesTransform* and *ShiftTargetTransform*\n",
    "\n",
    "Any EMNIST (sub)dataset is imported via `torchvision`. For example, downloading the MNIST dataset returns a object of the type `torchvision.datasets.mnist.EMNIST`. It is possible to work directly with this kind of object, but we want to make the code clearer, more robust and generalisable to other possible datasets (eventually your own dataset) to offer you a better PyTorch GAN framework.\n",
    "\n",
    "Therefore, we define another class called `EMNISTDataset`, inheriting from the more general `torchvision.datasets.ImageFolder` framework. `EMNISTDataset` could be easily modified to account for all types of image datasets (of course, this is outside of the scope of this project). The dataset imported from `torchvision.datasets.mnist.EMNIST` is then included as an attribute in the `EMNISTDataset`.\n",
    "\n",
    "Before defining the class `EMNISTDataset`, be aware that all images in the torchvision EMNIST dataset have their axes swapped for an unknown reason. To remedy this, we first define a transform class called `SwapAxesTransform` which corrects this fault. Also, a fantom class exists in the EMNIST Letters dataset, shifting all target values by 1. The solution is `ShiftTargetTransform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d824a39a",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "d824a39a"
   },
   "outputs": [],
   "source": [
    "class SwapAxesTransform(nn.Module):\n",
    "    \"\"\"Permute the x and y axes of images\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, image):\n",
    "        image = torch.transpose(image,1,2)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b95b2fa",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "8b95b2fa"
   },
   "outputs": [],
   "source": [
    "class ShiftTargetTransform(nn.Module):\n",
    "    \"\"\"Shift targets by given value\"\"\"\n",
    "\n",
    "    def __init__(self, shift):\n",
    "        super().__init__()\n",
    "        self.shift = int(shift)\n",
    "\n",
    "    def forward(self, target):\n",
    "        target += self.shift\n",
    "        return target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8a796",
   "metadata": {
    "id": "d7a8a796"
   },
   "source": [
    "### Import dataset ###\n",
    "With the dataset defined correctly, we can now import it to work with it. We'll do it with the `getDataset` function.\n",
    "\n",
    "The function will also split the dataset in a training and a testing set according to your preferences. You could also split it in 3 (with an additional validation set), but it will require to adapt the given code in the rest of the project.\n",
    "\n",
    "The first time you run the `getDataset` function on a specific hardware, you will probably have to wait for some time for the whole dataset to be downloaded. This can last for 10 minutes on your CPU. But don't worry, working with it afterwards will be faster as the data loaders (see below) will immediately have access to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95605371",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "95605371"
   },
   "outputs": [],
   "source": [
    "##### Import dataset and its subsets (training, (validation,) testing datasets)\n",
    "\n",
    "def getDataset(dataset_name, image_resize, interpolation_mode, transform_mode, split, number=None, info=True, source=\".\"):\n",
    "\n",
    "    # Import dataset\n",
    "    if dataset_name == \"MNIST\" or dataset_name == \"EMNIST_Letters\" or dataset_name == \"EMNIST_Balanced\":\n",
    "        path_data = source + '/Data'\n",
    "        dataset = EMNISTDataset(root=path_data, image_resize=image_resize, dataset_name=dataset_name, interpolation_mode=interpolation_mode, transform_mode=transform_mode, number=number)\n",
    "\n",
    "    else:\n",
    "        print(\"DATASET NOT CORRECTLY DEFINED\")\n",
    "\n",
    "    if info:\n",
    "        print(dataset)\n",
    "\n",
    "    # Split dataset\n",
    "    rng = torch.Generator().manual_seed(2472)\n",
    "    if len(split) == 2:\n",
    "        train_dataset, test_dataset = random_split(dataset, split, generator=rng)\n",
    "        return dataset, train_dataset, test_dataset\n",
    "    elif len(split) == 3:\n",
    "        train_dataset, validation_dataset, test_dataset = random_split(dataset, split, generator=rng)\n",
    "        return dataset, train_dataset, validation_dataset, test_dataset\n",
    "    else:\n",
    "        print(\"Split has not acceptable length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eebb81",
   "metadata": {
    "id": "69eebb81"
   },
   "source": [
    "By default, the MNIST dataset is selected. However, you can choose which dataset to download and how to download it: eventual resize of the images, transform with or without data augmentation and split proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb740ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "9cb740ef",
    "outputId": "58f1998b-c95e-4b01-f72a-342e4412810b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m transform_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnormalization\u001b[39m\u001b[38;5;124m'\u001b[39m   \u001b[38;5;66;03m# DON'T MODIFY\u001b[39;00m\n\u001b[1;32m     11\u001b[0m split \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.8\u001b[39m,\u001b[38;5;241m0.2\u001b[39m]       \u001b[38;5;66;03m# DON'T MODIFY\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m dataset, train_dataset, test_dataset \u001b[38;5;241m=\u001b[39m getDataset(dataset_name, image_resize, interpolation_mode, transform_mode, split, source\u001b[38;5;241m=\u001b[39m\u001b[43msource\u001b[49m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mclasses)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'source' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_name = \"MNIST\"      # Default for this homework\n",
    "#dataset_name = \"EMNIST_Letters\"\n",
    "#dataset_name = \"EMNIST_Balanced\"\n",
    "n_channels = 1       # DON'T MODIFY\n",
    "\n",
    "height = 28      # DON'T MODIFY\n",
    "width = 28       # DON'T MODIFY\n",
    "image_resize = (n_channels,height,width)   # DON'T MODIFY\n",
    "interpolation_mode = 'bilinear'    # DON'T MODIFY\n",
    "transform_mode = 'normalization'   # DON'T MODIFY\n",
    "split = [0.8,0.2]       # DON'T MODIFY\n",
    "\n",
    "dataset, train_dataset, test_dataset = getDataset(dataset_name, image_resize, interpolation_mode, transform_mode, split, source=source)\n",
    "print(dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b7a61d-1b99-4305-b8b7-25f4e22fd131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in ./anaconda3/envs/test_env/lib/python3.8/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5f5fd",
   "metadata": {
    "id": "7cc5f5fd"
   },
   "source": [
    "### Divide dataset into batches\n",
    "For training and testing of neural nerwork, it is impractical to use complete datasets. Indeed, computation and memory requirements would be unfeasible for the hardware. The solution is to divide the dataset in smaller batches, for which the process is affordable, and to iterate on each batch. Typically, the batch size is orders of magnitude smaller than the whole dataset.\n",
    "\n",
    "The function `divideInBatches` splits the dataset into batches and creates the loaders for the data.\n",
    "\n",
    "You can modify the value of parameter `batch_size` as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585891a0",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "585891a0"
   },
   "outputs": [],
   "source": [
    "##### Divide dataset into subsets and batches and create loaders for each subset\n",
    "\n",
    "def divideInBatches(train_dataset, test_dataset, batch_size, num_workers):\n",
    "\n",
    "    # Train set\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    n_batches_train = len(train_loader.batch_sampler)\n",
    "\n",
    "    # Test set\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    n_batches_test = len(test_loader.batch_sampler)\n",
    "\n",
    "    return train_loader, test_loader, n_batches_train, n_batches_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a5c830",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "c7a5c830"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'divideInBatches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mbatch_size\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# k = int(batch_size*1.0)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_loader, test_loader, n_batches_train, n_batches_test \u001b[38;5;241m=\u001b[39m \u001b[43mdivideInBatches\u001b[49m(train_dataset, test_dataset, batch_size, num_workers)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'divideInBatches' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "k = int(2*batch_size*1.0)\n",
    "# k = int(batch_size*1.0)\n",
    "\n",
    "train_loader, test_loader, n_batches_train, n_batches_test = divideInBatches(train_dataset, test_dataset, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a262527",
   "metadata": {
    "id": "3a262527"
   },
   "source": [
    "### Show samples ###\n",
    "\n",
    "During the whole homework, it will be important to show samples, either from the dataset, either ones your generate. Here is a function to help you visualize and avoid losing any plot that you once created.\n",
    "\n",
    "The function `plotSamples` allows to represent up to 20 images. You can specify whether they are generated by your generator or not (i.e. coming from the dataset). For the ones from the dataset, their label is showed as well.\n",
    "\n",
    "The created figures are stored in the folder: Figures. The figures are stored with a predefined name depending on the (date)time.\n",
    "\n",
    "You can of course modify this function as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e27f3e5",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1727106033252,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "6e27f3e5"
   },
   "outputs": [],
   "source": [
    "##### Plotting/Showing examples from the dataset\n",
    "\n",
    "def plotSamples(samples, epoch=None, source=\".\"):\n",
    "    now = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "    images = samples['image']\n",
    "    images = t.Normalize((-1.0,), (2.0,))(images)\n",
    "    names = samples['name']\n",
    "    generated = samples['generated']\n",
    "\n",
    "    if all(generated):\n",
    "        if epoch!=None:\n",
    "            plt.close(\"Epoch \" + str(epoch))\n",
    "            f = plt.figure(\"Epoch \" + str(epoch), figsize = (10,7))\n",
    "            f.suptitle(\"Generated samples epoch \" + str(epoch), fontsize = 20)\n",
    "            save_name ='Sample_generated_' + now + '__epoch_' + str(epoch)\n",
    "        else:\n",
    "            plt.close(\"Generated samples\")\n",
    "            f = plt.figure(\"Generated samples\", figsize = (10,7))\n",
    "            f.suptitle(\"Generated samples trained model\", fontsize = 20)\n",
    "            save_name ='Sample_generated_' + now\n",
    "    elif all(generated == False):\n",
    "        plt.close(\"Dataset samples\")\n",
    "        f = plt.figure(\"Dataset samples\", figsize = (10,7))\n",
    "        f.suptitle(\"Dataset samples\", fontsize = 20)\n",
    "        save_name = \"Sample_dataset\"\n",
    "    else: # Mix of generated samples and data from the dataset\n",
    "        if epoch!=None:\n",
    "            plt.close(\"Epoch \" + str(epoch))\n",
    "            f = plt.figure(\"Epoch \" + str(epoch), figsize = (10,7))\n",
    "            f.suptitle(\"Sample epoch \" + str(epoch), fontsize = 20)\n",
    "            save_name = \"Sample_dataset_\" + now + '__epoch_' + str(epoch)\n",
    "        else:\n",
    "            plt.close(\"Samples\")\n",
    "            f = plt.figure(\"Samples\", figsize = (10,7))\n",
    "            f.suptitle(\"Sample trained model\", fontsize = 20)\n",
    "            save_name = \"Sample_dataset_\" + now\n",
    "\n",
    "    f.subplots_adjust(wspace=0.2, hspace=0.4)\n",
    "    plt.rc('axes', titlesize=20)\n",
    "\n",
    "    n = len(images)\n",
    "    for i in range(np.min([20,n])):\n",
    "        image = images[i]\n",
    "        name = names[i]\n",
    "        label = name\n",
    "        if generated[i] == True:\n",
    "            label += \" (gen)\"\n",
    "        fi = f.add_subplot(4, 5, i + 1)\n",
    "        image_to_plot = torch.permute(image.cpu().detach(),(1,2,0))\n",
    "        color_map = None\n",
    "        if image_to_plot.size()[2] == 1:\n",
    "            color_map = 'gray_r' # you can change the color map if you want\n",
    "        fi.imshow(image_to_plot, cmap=color_map)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        fi.title.set_text(label)\n",
    "\n",
    "    f.savefig(source + '/Figures/' + save_name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ecbb243",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "executionInfo": {
     "elapsed": 2479,
     "status": "ok",
     "timestamp": 1727106035725,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "2ecbb243",
    "outputId": "bf408762-63d7-4c79-84db-4a8d3f44c9c1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(\u001b[43mtrain_loader\u001b[49m))\n\u001b[1;32m      2\u001b[0m plotSamples(data_batch, source\u001b[38;5;241m=\u001b[39msource)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "data_batch = next(iter(train_loader))\n",
    "plotSamples(data_batch, source=source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26e0a3",
   "metadata": {
    "id": "0e26e0a3"
   },
   "source": [
    "## Section 1: Train your GAN\n",
    "In this first part, you are asked to train and test a CGAN for the generation of fake handwritten digits (and letters).\n",
    "\n",
    "Let's just recall what training a model means in machine learning. It is in fact quite simple: given a model architecture, use an optimization scheme to minimize a loss function (representing the gap between the data and the model predictions) in order to find the optimal values of the model parameters. In this Section, all of these elements are treated one by one.\n",
    "\n",
    "Let's maybe first recall the global architecture of the a GAN model. GANs are deep neural networks composed of two parts: a generator and a discriminator. Those two parts are trained as opponents (hence \"adversarial\"). On one side, the generator tries, from random latent vectors, to create new fake data that can fool the discriminator into thinking they are really coming from the dataset. Meanwhile, the discriminator tries to distinguish between true and fake data.\n",
    "\n",
    "Conditional GAN (CGAN), introduced in 2014 by Mirza and Osindero, is a variation of the classical GAN architecture that aims to give control the generated outputs by inputting (in addition to the latent vector) a label corresponding to what should be generated. In particular, the generator and the discriminator both receive the label, i.e. the class, that should be generated or discriminated. During inference, this label can be chosen by the user, similar to prompts for LLMs like ChatGPT. The figure below illustrates the structural difference between GAN and CGAN.\n",
    "\n",
    "![image.jpeg](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABMTExMVExYYGBYeIR0hHi0pJiYpLUQwNDA0MERnQEtAQEtAZ1tuWlNablujgHJygKO9n5afveXMzOX///////8BExMTExUTFhgYFh4hHSEeLSkmJiktRDA0MDQwRGdAS0BAS0BnW25aU1puW6OAcnKAo72flp+95czM5f/////////CABEIAucEAAMBIgACEQEDEQH/xAAbAAEAAwEBAQEAAAAAAAAAAAAAAwQFAgEGB//aAAgBAQAAAADSsgAAAAAAAAAAAAAAAAAAACPRu4usAAAAAAAAAAAAAAAAAAAAK/F/G1QAAAAAAAAAAAAAAAAAAABX4v42qAAAAAAAAAAAAAAAAAAAAK/F/F1gAAAAAAAAIa5POAAAAAAAAAAK/F/G1QAAAAAAAAUeZDjzQAAAAAAAAAAK/F/F1gAAAAAAAAp+evfDm8AAAAAAAAAAr8X8XWAAAAAAAADMmrLYg0fQAAAAAAAAAK/l3G1QAAAAAAABDX6+e253nnvVoAAAAAAAAACv5dxdYAAAAAAAAVo6mTrVpFmzh+lX7AAAAAAAAAAr8X8XWAAAAAAAAHmdM4i5hvcXZD5n6YAAAAAAAAAr8X8bVAAAAAAAADPlAh0R8z9MAAAAAAAAAV+L+LrAAAAAAAABznWAgv8AY+Z+mAAAAAAAAAK/F/G1QAAAAAAAAeUuPPe7vofM/TCKoAAAW5QAAAAV+L+NqgAAAAAAAAAA+Z+mFHsAAA4vAAAAAr8X8bVAAAAAAAAAAB8z9MKPYAABHfAAAABX4v4usAAAAAAAAAAD5n6YUewAACO+AAAACvxfxdYAAAAAAAAAAHzP0wo9/M2rl/3z3P0HFW68oX/SO+Ao2+6EkGkAAK/F/F1gAAAAAAAAAAfMha0fluJMLWmgIJ4ObufPLLS+4z6gCj8x+ha3y31XQAAr8X8bVAAAAAAAAAAB8z9MKPfy1qWjPBoCKK1STcTS68d8Bjw70ORugABX4v4usAAAAAAAAAAD5n6YUewAACO+AAAACvxfxtUAAAAAAAAAAHzP0wo9gAAEd8AAAAFfi/jaoAACr4AAAnkAAAB8z9MKPYAABHfAAAABX4v42qAABW69AAAQXQAIYiScHzP0wpvQAAHN0AAAAFfy7jaohh9e2gBVkAAAILoAKjo85uB8z9MFXwAAD20AAAABX4v4usQeWDmpdAKsgAABBdACr6BzbHzP0wAAAAAAAABX4v4usU7gRczg89qyHmLo2gEE4ILoDz1ShqXpxHc9PmfpgAAAAAAAACvxfxdZHxOzbsrKlBg1/pLhiwV6dqC3DxbiqTS298reAKvyv1l7n5z6apahnVJDA+vAAAAAAAAAK/F/F1kfE7F1ZWR6DCrfT3yj84p37dCS1Qnh8fTXSrCArfKfW6ebFeoQ+ad2h0NYAAAAAAAAAr8X8bVKdx56i4sA56qyAAAEF0Bx2pSKdrn15b6AAAAAAAAAAr+XcbVK/s5zTvAFWQAAAgugBV9A5tgAAAAAAAAAK/F/F1hBGLYAqyAAAEF0AFPr0R3PQAAAAAAAAAFfi/i6wAAFXv0AABBdAAgj897sAAAAAAAAAACvxfxdYAABUAAAJpQAAAAAAAAAAAABX4v42qAAAAAAVMzTsvfPfI6t951h7dC+8ed8oJ6UNrm3TuueqF/0AAAAAAAr8X8XWAAAAAAMDS+c4u1YL3VVdzrH1vxcnd7K6twd8zVWqqZ1zmlodwNrVAAAAAAAK/F/F1gAAAAADMw5or8VPQreczT1NLilVvS0b1Lxeo86D2om4VNDrjbnAAAAAAAV+L+LrAAAAAAAAAAAAAAAAAAAACvxfxdYAAAAAAAAAAAAAAAAAAAAV+L+LrAAAAAAAAAAAAAAAAAAAACvxfxdYAAAAAAAAAAAAAAAAAAAAV+L+LrAAAAAAAAAAAAAAAAAAAACvxfxtUAAAAAAAAAAAAAAAAAAAAV+L+NqgAAAAAAAAeVOUloAAAAAAAAAAV+L+LrAAAAAAAAAgpznkN+QAAAAAAAAABX4v4usAAAAAAAAHFCY98QaYAAAAAAAAACvxfxdYAAAAAAAAKPVf2b174uAAAAAAAAAAV+L+NqgAAAAAAABnTY02mc9R3wAAAAAAAAAK/F/G1QAAAAAAAAzus2nojRy4QA+lAAAAAAAAV+L+LrAAAAAAAABnyEMdezZ5vAD5n6YAAAAAAABX4v4usAAAAAAAAFeDsEV2QAfM/TAAAAAAAAK/F/F1gAAAAAAAAUXQjltgB8z9MAAAAAAAAr8X8bVAAAAAAAAAqweOrM4APmvpQAAAAAAAEEd/F1gAAAAAAAAHEMsgAD5nfBOAAAAAAAr8X8bVAAAAAAAABXrJI/LFoAHylwM36a2AAAAAABX4v4usAAAAAAAAFWGQOO7gAfM/TBi37YAAAAAAFfi/jaoAAAAAAAA4oTARXJQB8z9MGLftgAAAAAAV+L+LrAAAAAAAACl6Ac3gB8z9MGLftgAAAAAAV+L+LrBzBLIAAAAAAAodwU70rl1HoAD5n6YMW/bAAAAAAAr8X8XWFLuxFFYkAAAAAABQ7r/ADmwkq63ebAAKH2gYt+2HlUAAB3YAAFfi/japTt+ildAAAAAABR7pcWOOa+l1zeAAGLfthQkAAAcyWQACvxfxdYqWw8q2wAAAAAAjpSgR2pgABi37YZ0wAAB5cAAK/F/F1kPsrI0Znz0RxvWwAAAAAKkfYc+3QAAxb9sM+UAAA8uAAFfi/i6zmCyydGVUtmY0wAAAAAFat1LHxYtAAAxb9sM+SvY4kEUrj3oB5cACPrzuvxfxdYpXQqz9mY0wAAAAABFFJMAAAxb9sM+L5iXvq/BB3xzL7xcizbVvjeitAPmJvpcC1dtV+L+NqnNO50q9WBmNMAAAAAAAAAAxM6YLU/ytqnQ09SqQVJL0MTqD6PVzeAHz77RU10Ed/F1gq+LPQZjTPKgAABNMAAAAABi37YZ8scnMcvHQHnvnMj3y4AhmVJJ1fi/jaoADMaZVkAAAILoAFbjz3ux6AADFv2wz5QAADy4AAV+L+LrAAMxplWQAAAgugB5TkCO30AAGLfthnygAAHlwAAr8X8bVAAZjTKsgAABBdACp0BzbAADFv2wz5QAADy4AAV+L+LrAAMxplWQ4+d09IBSuggugDynBn6k44tdAADFv2wr1wAAHt3oAAr8X8XWAAZmLdO9cw1HGu8zQdz8QyNL6Ip5YDv1sR4H0lK1DZYQAWtwMW/bAAAAAAAr8X8XWAAZkWkV7BV+clguTVZu6k0MUu9bILoHnnMKhxPSrNLQ6nAHzP0wYt+2AAAAAABX4v42qAAzGmVZAAACC6AFKRWsiO56APmfpgxb9sAAAAAACvxfxdYABmNMqyAAAEF0AK3noPLQAfM/TBi37YAAAAAAFfi/i6wADMaZVkAAAILoAKvnRytgA+Z+mDFv2wAAAAAAK/F/F1gQ+S9BmNMrugAAEF0ACOEllAA+E1Q4+jmAAAAAAAr8X8bVFeLv3ha6Mxpit4AAAn7AAAAA+Z+mAAAAAAAAV+L+Nqlbz0I7nrMaYAAAAAAAAB8z9MAAAAAAAAr8X8XWcVuwPLTMaYAAAAAAAAB8z9MAAAAAAAAr8X8XWVuIO5wjnZsF/wAeePPHjzx488ePPHnjx488ePAA8AD6cAAAAAAABX4v4usq8/N61TQz9Cxxnln317699evXvr31699evfXr3169AAAAAAAAAAABX4v4usrV8XS58ry6nN0AAAAAAAAAAAAAAAAAAV+L+LrOK3ccgeWgAAAfPWLViFmWLPvs1bjTZNXY4itwOIO70Pdj5j6PH14nkU6rP1Wz7l7inpeQdV78oAAAACvxfxdYreehHb6AAABgXqGLt8ZG5h7LPauj7kTY16TD1Z4KG1kWbOr8tctUPbKndg979ucYWjLR581GL9rMAAAAAr8X8XWFeLv2P210AAADn5yWrc7p9y8xW4at60rUbHliDi1RkmEljMWPYpqE/k8C0j8eJalw2OwAAAAK/F/F1gRcy9AAAAAAAAAAAAAAAAAAAV+L+LrAAAAAAAAAAAAAAAAAAAACvxfxdYAAAAAAAAAAAAAAAAAAAAV+L+LrAAAAAAAAAAAAAAAAAAAACvxfxdYAAAAAAAAAAAAAAAAAAAAV+L+LrAAAAAAAAAAAAAAAAAAAACvxf+YtgAAAAAAAAAAAAAAAAAAACLSv/wD/xAAXAQEBAQEAAAAAAAAAAAAAAAAAAgED/9oACAECEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAZLaAAAAAAAAABA2gAAAAAAAABkhYAAAAAAAAAQNoAAAAAAAAAMltBugCQAAAAAAAAsAJwAAAAAAAAWAGSAAAAAAAALwAZgAAAAAAAAsAMkAAABdADngMzdCwAnAAAAHTQBMBOFaGgDAAAADpuAamAjcbQAAAAAAOm4BqYCNFAAAAAAA6aAJgJwrQAAAAAAXQAiQS3QAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxoAAAAAAAAAGSVoAAAAAAAAAQFgAAAAAAAABAWAAAAAAAAAE4bQAAAAAAAAAMzdAAAAAAAAABklgAAAAAAAABkjaAAAAAAAAAGSFgA0AYAAAAADJG0AFaAMkAAAAAE4VoAVoAQAAAAAAzQAKADYAAAugBEglugArQAgAADpoAmAgVoAVoAQAAB03M0zdTARuFgAoAZgAAHTcA1MBDSgAAAAAAdNAEwECtAAAAAGSrRegCMBjQAAAAAQK0AAAAAAAAAZI2gAAAAAAAABkjaAAAAAAAAACcLAAAAAAAAAAxoAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAf//EABgBAQEBAQEAAAAAAAAAAAAAAAABAgME/9oACAEDEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAXszyAAAAAAAAAB6FcuYAAAAAAAAAvozU4AAAAAAAAAB6SY5AAAAAAAAABrtccQoAQAAAAAAAANABIAAAAAAAANABIAAAAAAAANQAsgAAAAAAAA0AEgAAADMAGqCKDQASAAAAMQAa0GYaoUAQAAAAxKAmtBgXQAAAAAAMSgRrQYF0AAAAAADEAGtBmGqAAAAAADOQC6oIUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALrMAAAAAAAAABvsccAAAAAAAAAB6JpngAAAAAAAAAHoI4AAAAAAAAAB16HLmAAAAAAAAADe8YAAAAAAAAAB06pwgAAAAAAAAAvoGeAAAAAAAAAA6dJTzgAoAgAAAAANd4TgAFoAZAAAAAB06pwgAWgBkAAAAABYABQAuQAAM5AG6CS0AFoAZAAAxABrQYGqAFoAZAAAxLUWJrQYF0ACgBAAAMSgRrQYF0AAAAAADEAGtBmGqAAAAAGVozABqgigAAAAAwNUAAAAAAAAATIugAAAAAAAABMi6AAAAAAAAADMNgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP//EAE4QAAEDAQIHCgoJAwMEAwADAAECAwQABRESExU0U1RzEBQgITEyM1GSsQYWNUBBUFJxgZEiMFVgYXKCodEjJHRCYsFDRGOyNpOiJcLh/9oACAEBAAE/AGGHZTsn+5cQEOEVk13XXayY7rrtZNd112smu667WTHdddrJruuu1k13XXayY7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJjuuu1k13XXaya7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smO667WTXdddrJruuu1kx3XXaya7rrtZNd112smO667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJruuu1k13XXayY7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJjuuu1k13XXaya7rrtZMd112smu667WTXdddrJjuuu1k13XXaya7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smO667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJruuu1k13XXayY7rrtZNd112smu667WTHdddrJruuu1k13XXayY7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJruuu1k13XXaya7rrtZNd112smu667WTXdddrJjuuu1k13XXaya7rrtZNd112smu667T0B1tpxe/HTgpJqzVFUFkqJJ49yzelm7X7+y82f2aqsvMWfj37lm9LN2v39l5s/s1VZeYs/Hv3LN6Wbtfv7LzZ/Zqqy8xZ+PfuWb0s3a+uHX2muesAnkHpoy3FdHHV71EJrHS9G12jW+nk8+Of0qvpqSy6bkq4/ZPEfuDLzZ/Zqqy8xZ+PfuWb0s3a+t3X1rUW2TycSl9X4Cm2UIvI41HlUeMngONIc5w9x9IpD62SEvG9B5F/z9wJebP7NVWXmLPx79yzelm7X1tKcVeGUG5SuMn2U0hCUJCUi4DhEBQIIvBqMstrLCj6L0H8Or1/LzZ/Zqqy8xZ+PfuWb0s3a+tmfplbx/1q4vcOIUpQSkqUbgBeTTU6I8sIbfQpXUDSJ0NxzFofQV+yDwZAIQHE85s4QpKgpIUOQi8evpebP7NVWTmLPx79yzelm7X1rJVgR3lDlCDTacFtCepIG4+Vw7Xvau/u0XfrFMMIYRcOMk3qV6VE+k7pIAJJAAF5NIWhaQpCgpJ5CDeKIvBBqEb4zX4Aj5G719LzZ/ZqqycxZ+PfuWb0s3a+tZYvivfkNJN6UnrAqXOaipOEFKXdeEpBN9WkwDBEgqvkFaVpUB+wpmWH4wdQk4VwvBBFxNJtF0RxIdYubLYULjeSVG4CjNW22ta2/ZCLvSpX+kX0uYtCZoWlN7DYN4PKSL7qhtFmKw16UoAO4ldvDNWmSySSkqrG+FGgjVjfCjQRqxvhRoI1SrSt+GlC322AlS7vXUvNX9mqrLzFn49+5ZvSzdr61UApJSeQi6o5OLCTyoJQfhuut4xpaLyMJJF4pcZtbAZ5EpCbrvQUclORcakYbqioLSpJ9AKaNnIUHwp1ZxpvP7fxTaMBATeTd6TT6yhpRHLyD3mmUYtpCPZSBwPCjNI3+QPXUvNn9mqrLzFn49+5ZvSzdr62fGJeDv+hdwV+B9B+obGPfHsNH5q4PhRmkb/IHrqXmz+zVVl5iz8e/cs3pZu19bKSlaSlQvBFxFHCjEJWSW/wDSvq/A8LCW+Shnk/1L9A91NtoaQlCRcAOD4UZpG/yB66l5s/s1VZeYs/Hv3LN6WbtfW5AIIIvBpUQo42F4P+08aaKpCeewT+KDfWPOhe7BoLfVzI6v1EJoRXF9O5xewniFJSlACUgADheFGaRv8gcF51LSLz7gOs0ce5xrcKf9qKxR0rvbNYo6V3tmsUdK72zWKOld7ZrFHSu9s1ijpXe2axR0rvbNYo6V3tmsUdK72zWKOld7ZrFHSu9s1ijpXe2axR0rvbNYo6V3tmsUdK72zWKOld7ZrFHSu9s1ijpXe2axR0rvbNAPo40OlX4Lpl1LqbwLiDcR1Hz+Xmz+zVVl5iz8e/cs3pZu1+4fhRmkb/IHBc+lJ/Ij91ebI+jJT/vQQf0+fy82f2aqsvMWfj37lm9LN2v3D8KM0jf5A4Jzp38qfNv+5Y9yvP5ebP7NVWXmLPx79yzelm7X7h+FGaRv8gcE507+VPm3/cse5Xn8vNn9mqrLzFn49+5ZvSzdr9w/CjNI3+QOCc6d/Kncy5MW+80zBxmLURUK2g/I3s+wWXaakylTnWFRiGki8OUSAbiRuXg7kuVJZdjpZjl1KzctXs7l4pxRDa1JGEQkkCoEiRIZK32C0rCuCavG4CDyGhaLRnqhYCsMC++iQBeSBuXjc/7lj3K+pmT2ISmsfeELNwXygGm3G3UBbawpJ5CDeNyfLfiMqeRHDqEC9f07jUGSqVGQ+W0oCxeAFYVQ5sqSs3xEJaCiMZjL77vMZebP7NVWXmLPx79yzelm7X7h+FOZx9vXjOxqkmvGdjVJNeM7GqSa8Z2NUk1BnInOPupbWgAJFytywvKNpfnq2fLFn4HPvR/7VFJ8YpmzNKDYceFoofDyjxLqVLWzYrQZlF3DWUYfIQKFgONpYdiyCl7lUVVPZdftxLAcKCtsAkVaMYQ3bJYQskJWf3VUtjfNvlguLQlSBfd+WosALtGTAx7gYF5NWUVtG1Y2GShtK6YJ8XJe2/inrOSLIRNLrhdATUx7G2VBL0soCh9L0qXUdTbFpxN6pfbQtSQQ56abgM5eWxevBSMOmmMr2lLD61htokJSKs4rhWo/ACypq4kVYsAzAVreWENOghO5OlPRVMONRlvqvUMBNZctH7EfrLlo/Yj9ZctH7EfrLlo/Yj9ZctH7EfrLlo/Yj9ZctH7EfrLlo/Yj9WlaUuXCeadsd9A9v2aiTpUNeEw6U9xqx7Skzm73oikdTnIk042lxtbahelSSD7jVkb5Wy9ZxvCGXlJcc/D2RSUpQkJSAABcAPMZebP7NVWXmLPx79yzelm7X7h+FGaRv8gcE507+VO4LItVl992PJaRjFmoNjuNyt9S38a7TVmuptOTKK04txBFw5aybbDaHWEPtOtL0lCwhkzepcGMw8PCrJVqSMS1LkIxLfs0bOdyuiYFIxaUXXVaVnPS5EN1CkANKvN9ZOeyxv3CRi8GmLOeatV+WVIKFpIAqNZb7L9oOFaLnwvBpqx5CLJfhlbeGtwKp2z3l2QIQWjDCEi/3GpFjSVR4OLcRjY9Lsu0npcaU88yVIUCU0/ZszKe/I7rYvuBCqfsuazMckwHUJLnOSqrOst5l52VJcC311Y9nuwGnUOKQSpd4u3P+5Y9yvqbYjzJjKYrFwCze4s1A8H4US5SxjnOtW4+6ppGEllbh9lF1WG0+y08l9haHFuFwqPmUvNn9mqrLzFn49+5ZvSzdr9w/CjNI3+QOCc6d/Knzb/uWPcrz+Xmz+zVVl5iz8e/cs3pZu1+4fhRmkb/ACBwTnTv5U+bf9yx7lefy82f2aqsvMWfj37lm9LN2vmpkKUSGUYQ9om4VhSv/F8jWFK62vkawpXW18jWFK62vkawpXW18jWFK62vkawpXW18jWFK62vkawpXW18jWFK62vkawpXW18jWFK62vkawpXW18jWFK62vkawpXW18jWFK62vkawpXW18jWFK62vkawpfW18jWMkp4yhCvym4026h1N6fiDyjznwozSN/kDgqzp38ifNhnLHuV5/LzZ/Zqqy8xZ+PfuWb0s3a+aSSSENg883H3cpoAAAAXAear/putuD0kJV9ct9CTgi9SuoVjXzyJSn38dXv6RPZrGPjlCFftSZCCblXpV1Hh+FGaRv8AIHBkpKFpeA4gLl+6gQReDeD5oSACSajgrcLxFybsFH8+fy82f2aqsnMWfj37lm9LN2vBefbZAwjxnkSOMmsKY5yJQ0n/AHfSVWIkemWrsprAmI5HkL/BSbv3FIlDCCHUFtZ5L+Q+4/Vv9Ox+vzaRzB+dHf8AWqcU6bkG5HWOU+6kpSkXAXDgFIUCCLxSVqZ5SS3+6aBBAI4PhRmkb/IHCVERfehSkfl5K3svWF/IVvZesL+Qrey9YX8hW9l6wv5Ct7L1hfyFb2XrC/kK3svWF/IVvZesL+Qrey9YX8hW9l6wv5Ct7L1hfyFb2XrC/kK3svWF/IVvZesL+Qrey9YX8hW9l6wv5Ct7L1hfyFb2XrC/kK3svWF/IUIiL71qUv38nqCXmz+zVVl5iz8e/cs3pZu14D7xbCQgXuLNyE0ywG71qOG4eVZ4C20OIKFpBBptS2HEsrJKFdGs9x+qf6dj9fmz/MH50d/1j6ipQaB/FRoC4XDhtHFrxZ5p40/xwfCjNI3+QPXUvNn9mqrLzFn49+5ZvSzdrwI/9V1x89ZQj3DhPtB5pSD8D1GozpdZSo84XhXvHDwkklN4vA5Nx/p2P18F7wgs1pZRhqX+UVFmRpjeGw4FD9x9SxJYkAqZdSsDlKTw3+YPzo7/AKkqAuvIF5uG61eoFZ5Vm+pj70dlTqGQ4EglQwrqTaK1QBLDAJUQEoC+WmFvrRe8yGz6AFYXBdBwCRyp4x8KSoKSFDkI4HhRmkb/ACB66l5s/s1VZeYs/Hv3LN6Wbtd15RQ04sehBPyqKkIjsp6kDdkS5TThKY17COeskA/CmVuLbC1owSbyB6QPRfuiZEiyJLbz6EXrCwFG7lFZWszXGe1WVrM1xntVlazNcZ7VZWszXGe1WVrM1xntVlWzNcZ7VW7KiuNtyYk1Afa9hfGUmoHhSsXImo/Wiky40pcdbDqVj6XAt95bVmu4BuKyEVAZgwrJQ+62CFIClm6/nVZjlkomPriuu3lCiUEXIoWnaUzHPNS2GEI5G1EXmlW1IcscyEEIeQ6EGn5luNRGZynmw2q76FWhbD4bhIYKEOPoSsqVyJBqNacyPPajyJLT6HbgFooz7YfnS4sZY+itX6QKmv2qHkNJebYbCBe6si5Sqs6fPl77jB9tTqBeh2rAW8yxKfKxiEXlaaYet2e05KZfQhAJwUULZfdsZ59JCX21pBqyXrVkqQ++Uhgt8CWtDbOGtQCQpJJPvrKtma4z2qytZmuM9qsrWZrjParK1ma4z2qytZmuM9qsrWZrjParKtma4z2qytZmuM9qpsyypcV1kzWeMcRwuQ1C8IpsQ4DpDyKYtiFMYXinLl4PMVxGki5IHUBTi20NqU4QEAG8mrGQESn2HAsFr6TKFehK9yNLEkrKW1hA5qzyKpRwUqN19wJuqM+JDDbwSUhYvAO61aUBpAbclNJUm8EFVZWszXGe1WVbM1xntVlazNcZ7VeEM2JIjMJZfbWQ+PXUvNn9mqrLzFn49+5ZvSzdruvJK2XU9aCKjKC47KutA3XJ8YuBb+GloG9oYJuWeumVrcaStaMAkX4O6bPhzZMh19kLuUECshWTqiayFZOqJrIVk6omshWTqiayFZOqJrIVk6omrdhQIzLbMaIC+6ageDD7ty5SsUn2KagxYS2EMNBPOvPpPAtGGJsR1i+4nmmo020YTG837OW8E8Sas+FNNpOLkMFsPML5BxC+moy4IdZfsovrv+gun4ck2KsbzShxbqTi2gatBh9dhMNJaWXAhq9IFTbPkYmzpIjl3FMIQ41UNsvzGi1ZKGWkEErWDfVlsPt2taLi2lhCiq4kVMYcRbDrsmG7IaPRhNWNHkNWlKU5FUylaDd7NWTGkpamQHoziMaD9Ooku0bNjriGA4tYJwFCk2ZKZsOQktqLzq0HAFWahaIEVC0lKg2AQeBMbQ6wULF6VKSCPjWQrJ1RNZCsnVE1kKydUTWQrJ1RNZCsnVE1kKydUTWQrJ1RNZCsnVE1MsyxokZ19cRFyBUKwp004ZQGmj6VVHsOFDZWpKcN0J56qSb0g9YrEznZLZeDOJSb8BJJN9SIcw2i3LZxIwEYJBJvUKlrKIby1XgpbJOCSKShcaLBjtlQLqkpWq/kuTebqVIO9bRwXCq9ZQ0Cf0UHnGI7q0rUHGEKaxfKi9N3HUZtxDhC3b1YAvThlX6txFkWc+nGuxgpaySTWQrJ1RNZCsnVE1kKydUTWQ7K1VPrqXmr+zVVl5iz8e/cs3pZu14Eb+mt2OfQSpH5VbuCni4hxbrzoZbUs8gFRmy2ykK5xJUr3q4eLRh4eCMMi7C9N24/07H6/NpHMH50d/1K20Luw0hVxvF45DuEXgimuJJQeVBu3ZcZcnARjcFr/Wm7nCloQsYK0pUOoi+gyyL7m0cZBPF6RWLbvUcBN6ucbuX30httsXIQlI6gLqdJCDdyniHvNISEpSkegAevpebP7NVWTmLPx79yzelm7XgSGSvBW2bnEc0/8GmX0ugjmrTzkHlHAUpKElSiABymkBUlxLigQ0k3oHtH2vqn+nY/X5s/zB+dHf8AWPJKFB0cnIr+fqGhjHMP/Snm/iev1/LzZ/Zqqy8xZ+PfuWb0s3a8F2Oh0hRvSsci08RFXzG+VKXh2FVvpfpivfIGsdKXzI+D+K1DuFCMVkKfXjCORPIgfVv9Ox+rzZ/mD86O/wCtUhTPGAS3+6aBCgCDeOASACTQCnuS8N+k9fuoAAAAXAev5ebP7NVWXmLPx79yzelm7XzSSLghz2FXn3GgQQCPNV/TcbbHWFK9w+uUwknCSShX4VgSE+hKv2r+tof3FYEg+hKfeb6THTeCtRWf2+4MvNn9mqrLzFn49+5ZvSzdr5qWHG+hULvYVX9zokdqv7nRI7df3OiR26/udEjt1/c6JHbr+50SO3X9zokduv7nRI7df3OiR26/udEjt1/c6JHbr+50SO3X9zokduv7nRI7df3OiR26/udEjt1/c6JHbr+50SO3X9zokdusGUr0IR+N99NMpaBuvJPKTyn7py82f2aqsvMWfj37lm9LN2vqibMahR1POe4Aekmt828UY3ebGDo8I4dQZjc2Mh9AIv5QfQaC0EkBQJHKAaKki+9QF3LQUlQvSQR1igtBUU4Qwuq/joqSOUii4gJCipISfSTxU88hphx7lSlBVSZjr0eK9HaBDi04QUrmpNAg8hFAg8hFJWhXNUD7juWpbBgPNNpaw+LDc/BNAggEG8EXirRnb0iOvN4K1IKRd7zQIPIRV4vIvF4oLQokBQJHKAaK0JvvUBdSnG0kBS0gnkBNE3C80laFi9Kgr3G+sNHtDlu+NRXH3Gr320oXhHiBvF1JcQu/BWk+41FmKflTWSkAMKSAeu+rXtBcCO26hsLKnQimZjb8MSWuMFBVVnyjLhMyFJCSsGkrQsEpUD7jUac1IdktgXYleCTRIF15FXi+68VjG8PAw04XVfx0SBykUJpNo71ASUb3xuF8bqvBJF49XS82f2aqsvMWfj37lm9LN2vqi3CA7ZhX0Ylpwqlif9DehYHtYy+nbSkqsiWfoJWJOJvap6MW22lQ7MfZebUCHCR+9bzZl25LD4vQlls4FYZgIt1EfiS0WygbSlRP7NBZs19MgAKD94vvp+MJtrxESNRCnE1LbhGcGhGdklpkJDI5jdRGkri20y4xgIR9JLRN4QbqxLTVmWMUIuK5bKlUh1NmWhaKV9E40ZCKdS8zZsNBCyua/hvBPKoGgwtqXEciWc9HucAcvIuUg7iH99LtJ4w5LqXwW21oReAkUJ73i8ReUvNrDC6teyYUWzStlGCtBR+uiRBtorJualM3/rbpxb6LKfmC8OTpI94RTsctBhcOzH2HW1j6ZUOMVvFiZbc8PgqQhDRwKfjFEqY5KgKlNuLvS4g3lAp1yCuzILeOfeQXLkoA+m5g+g1GTirZh4uEYqXG1gi/n1ZUFh6VOkOAqU3NcwKYUzkPBeW4ErkqFyBepfHzawA1aFnKagLiguFN5PPqzfKVr7Rurd5ln/5zVL//AIuU+1yRZQUUdSHKLq8lWPGCVqQ8peGlHKoJNNsranRHI0B2OCcB28i5Sai2bGdNstIaAIUUN1JedmxYZQfpRYpeV70EJp2SXXrQntcjERKG/esX0bKhiyC9d/WDGNx3pwrr6UjKEixQ+Tc5HUV1PL8G0cGCzeRA7Avqx2owhodZUVl3jWs8pV6ul5s/s1VZeYs/Hv3LN6WbtfVFp4txosORH3krHK2AbqCLQwQ0XLSLOyQFdq+mmI7cSRFyfOLTq7+aL00GpLhbTKTPeZQQQ3ikDtEGkOlua/K3jNvcQkXYCaAQXZy1wJqxKCQtOAmsRJUhLDuUVxdHikAkCsZdORKEGaCljFBOAmnxIMtyTHZnMKcACxikKqM0WFyf7eetD6LlgoReTSGVhiOyticsMPpcR/TRyJq0UItAslcGcktn0ITU1xExkNmBOSUkKQoJTekimkyS+09LanvlrjQMUhAp+a48w60IU1BWgpvCE/zUSTvWM0wiBNuQn2E0Wm1LnYUGdi5V2EjATxEU5GlPshl/KK0J5gxSBVpXWgyltcKagpVeFBCafW0/D3oqzZoQEgC5KaDcla2t9pnvttm9KMUhPapt4tzZMkQpt7wQCMBPoopltuvKiJnModWVrRiUKpUcBiMhiLPbcYJKHMBJJKqDT++WJS02gp9B5S0i4iobxib4uhTTjXlO8xPpoxhvNDAizwpDxdQ4EJ4jS2ZTq2nncoKebVehWKQAKjvFh+W8IU0l9QJGAn+amumWGAYU1OKfS7zE+ipzqZsZbDlnzOwmiygwWIwhzwpk3tuhCbwaZD++G35TU59bfRjFIQBTCnGJr76I07Ad41N4tFRW2oy5hECaRI5QUJqEluJDXF3hNWhd+FehNYiVit7HKBi6PFIv7V9FY31FfTAmpxCChKQhNY47/wB97ym34nFXYCahrMNx8tw5uLcVhBvATck1HeL6MIsut8d1ywAfVsvNn9mqrLzFn49+5ZvSzdr9/ZebP7NVWXmLPx79yzelm7X7+y82f2aqsvMWfj37lm9LN2v39l5s/s1VZeYs/Hv3LN6Wbtfv7LzZ/Zqqy8xZ+PfuWb0s3a/f2Xmz+zVVl5iz8e/cs3pZu1+/svNn9mqrLzFn49+5ZvSzdr64JABJIAFGa3yNpU5+UcXzNb5kHkjge9db5fHLH7K6RMZJCVXoV1LF33Bl5s/s1VZeYs/Hv3LN6WbtfW776WQPSo8SUjlNYtbpCnzf1IHNHAUlKgQoAigHGONq9SPSj+KadQ6gLQbx6/l5s/s1VZeYs/Hv3LN6WbtfWzjiWkKWrkAppKiS65z1f/kdXDUSw5jk809IP+aBvAI9fS82f2aqsvMWfj37lm9LN2vraScN5pr0D6au4bjkyI0sockNJUPQVAU5Lit4OG+2nCF4vUBeKSpK0hSSCki8EcAgEEGoajgKaPK2q74co9fS82f2aqsvMWfj37lm9LN2vrYfSkSFdRCfkNy22MOGXk9IyoLFRgmbi5biBdd/SRy3cDDQVFOEMIDk3GTdLWPaaB+R9fS82f2aqsvMWfj37lm9LN2vrZHE9JH/AJL/AJgU44hpBW4oJSOUmm3mbRWvjvYaPN9s/wAVYslpvHQyvmOnFH2hS5j4ecaRGw8AA8643ElNJnhx1SGkhQS5gHj46M8kpUhq9tT4aBv5TTAC58x32Qhr/k7kyeIUltWJccvbIuRXjINQk14yDUJNeMg1CTXjINQk14yDUJNeMg1CTXjINQk14yDUJNeMg1CTXjINQk14yt4aAqG+m8+s5ebP7NVWXmLPx79yzelm7X1s59CX+DiP3TwG2Ah192+8uEfAJFNRi1elDhCC4V3Xcd6jfdfWTuJpAeIS2tRSAPbpiMGVuqCyQtZVd79yKMJx9z8Qgfp+r8Jejg/5I9Zy82f2aqsvMWfj37lm9LN2vraU0XG7089Jwk+8U24HEBQ4by1ABKOes3JplsNNpQOQD6vwl6OD/kj1nLzZ/Zqqy8xZ+PfuWb0s3a+t3mVtrLrQvv56P+RSHEOJwkm/guOpRcOVR5EjlNR2FJJdcuLh+SR1fWeEvRwf8kes5ebP7NVWXmLPx79yzelm7X1w7FQtWGglC/aH/IoiU3zmwsdaP4NY8DlbdH6DWPv5rTp/Td30ESnPQlodo0zHbavIvKjyqPGfrfCXo4P+SPWcvNn9mqrLzFn49+5ZvSzdr65W42jnrSn3m6t+RdOj50h1pfMcSr3G/wCv8JSAiFtxW+o2na7QrfUbTt9oVvqNp2+0K31G07faFb6jadvtCt9RtO32hQIIBBBBHER6sl5s/s1VZeYs/Hv3LN6WbtfW70hDRCQCpZ5EiiH3ekcKR7KP5pMdlPI2O81gp6hSmGVcraaCHmuidN3sr4xTUlK1YC0lDnsn/j63wnYbWISzpcCvFqytGvt14tWVo19uvFqytGvt14tWVo19uvFqytGvt1a9iQIkB55pCgsXVAzCJsG+71ZLzZ/Zqqy8xZ+PfuWb0s3a+tpD5QQ23xuK/YddNthsH0qPKo8p4TjaXE3K+BHKKjvKwsS7z+VKvaH1nhL0cH/JHC8IvJEj9FQMwibBvu9WS82f2aqsvMWfj37lm9LN2vrVxxLaFLVyJF9MpVcXF89ZvP8AH1DzZWm9JuWk3pPUaYdDzSV8l/KOo/V+EvRwf8kcLwi8kSP0VZ+YQ9g33erJebP7NVWXmLPx79yzelm7X1rLOEplr2lXn3J+qjHAfeb9CrljuP1fhL0cH/JHC8IvJEj9FQMwibBvu9WS82f2aqsvMWfj37lm9LN2vCUpKRepQA6yaMyID07fzpDzLnMcSr3G/wBWu8cz3Nd53H3i0EBKcJazckUzaSVwHJakXBGF7jdTDhdYacKcErQFXdV+644htBWs3JHKabcQ6hK0G9KheDuDilsHrSsfV+EvRwf8kcLwi8kSP0VAzCHsG+71ZLzZ/Zqqy8xZ+PfuWb0s3a8EvOvkpYuCByuEf+tJhsg3rBcV1r46CEAXBIpcaO5zmk++641gSGONtRdR6UK53wNNOodQFIP8j1W5xTPe0P2O5NDhiSMWCV4tWDTrrK7NhQGj9J0tpXTkmSmTiGmkdGoj3JoznMYhjBCXQ2FuG4rCSfQAmhLdK2GQgB5aCtV/IhIp6W67ZslVwCissou9N5wKabDTbbaeRKQBuTn5bL0cxo+OUAskVlK3fsqspW79lVlK3fsqspW79lVlK3fsqspW79lVlK3fsqspW79lVlK3fsqspW79lVNNsTzHS5Z5QEOhXC8IvJEj9FQMwibBvu4SlJSCVEACt9g9G0tQ6+QfvW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXV8xW+XNXX8xTcltagkgoUeQK8xl5s/s1VZeYs/Hv3LN6WbteA+S87vdJISBe6fw9mkpSkAAAADiHBfTiF74QNqOsdfvFAggEeqpYwVsu9SsE+5W5OYefYCGnShQWDy3XgUiK45JRJkFN6AQ2hPGE0mOBJcfKrypCUAdQFGMQ+t5tzBK0gLvF/JRiHHB5LqgvF4ski8kX30mzAhltsPH6C0qSSPZpCAhCUgk3AC87kcYch1foSAgd58x8IvJEj9FQMwibBvu4ThxzygeY2fmrzVaErSUqFRnFKSpCjepBuJ7j5hLzZ/Zqqy8xZ+PfuWb0s3a7pIAJNQhe1jTznSVnhEAgg8hFQyQ2po8rSyj+PVTrYdbUhXIoUytRBQvnoNyv5+odcwE8QvUTckdZphoMtJRfefSesnzHwi8kSP0VAzCJsG+7hNf9Xar7/No/Tv+5HmEvNn9mqrLzFn49+5ZvSzdruyTdHe2au6mBcw0B7A3ZkULfCw64Xz0QBuCAKZaDLYReVHlUo8pJ3ZUu0I819MWHjkkIJNZTtz7JrKdufZNZTtz7Jp22LYZbU45ZlyRUGQZURl8pAK03+ppDClEOt9IkdodVNupcF44iOIg8o4TjiW04SjUdlRVjnRcr/Sn2R5l4ReSJH6KgZhD2Dfdwmv+rtV9/m0fp3/AMqPMJebP7NVWXmLPx79yzelm7XdWkKQpJ5CCKhqKozYPKkYJ96eLdMa0UHGNPt4bnSYQ5PdTLeKaSgqKrhxk+k7sT6Rfd9t03e5PFwLZ8ly9nVjeS4ez9TvRkuHDSShz2hRW810rZu9pHGKQ80vmrSdxTrSOctIoOOOcTLZP+5XEmmowSrDcVhr/Ye4eZ+EXkiR+ioGYRNg33cJr/q7VffRISCSQABeTW/Yess9sUlSVAFJBB9Ipt5l4EtOoXdy4Jv4OOZxuKxiMZ7F/HuuONtJK3FpSnrJuFJUlaQpKgUkXgjkP1Mfp3/yo+sU8ykkKcQD1EisNGDh4QweW/0Uh1tfMWlXuN+5LzZ/Zqqy8xZ+PfuWb0s3a8DN5BJ6N4/JfCkuEANN9I5xD8B6TTbaW20oTyJAA4Fs+S5ezqxvJcPZ+qVsMuc9tB94reUXQppEdhHNaQD7vNfCLyRI/RUDMImwb7uE1/1dqvvqdmUrYr7qsayocyGXHkEqwyKsorhWs/BCiW6siZGZhzX0sYCUEXgKJvoW1aGLTIMEFgn0Gp9rpjNsYtsrceAKEVFtd8y0RZcbFLXzaVb0gvPsNRCtxCyE3Uh1o29gli53F8+8+xWW5bi322YWGps0i3pTzBWzCvKBe4ak2gzMsVb62bwFgKRfTtqbxgQFoYBS4jkvpVtymXmt8wsW05U+03mZKIsaPjXSKi2vIeW+wuLdIbQSEA1YL74fk3t3oJvcWTzKy1OfLiocLDaRTdspds56Uhv6bXORUC1pE15sCKQ1ccNe4062iQ9hrSm9KOU1vmPpm+0K3zH0zfaFb5j6ZvtCt8x9M32hW+Y+mb7QrfMfTN9oVvmPpm+0K3zH0zfaFW1JehvNzIcgXK4nEX3ioPhNFeuRJGKX+1JWlaQpCgpJHEQbwa8IoaFwjIQ2jGtLC6U+iVGYYjpTe80D+DaKiw40RAQw0lHedyXmz+zVVl5iz8e/cs3pZu14C0IcQpCxekig45F+i7epr0OcpH5qQtC0hSFAg+kbq5Qwi2yMY5+w95phgtlS1qwnFc5X/A4Ns+S5ezqxvJcPZ/cDwi8kSP0VF8HI70ZhwyXwVtpVXixG1uTXixG1uTXixG1uTXixG1uTXixG1qTVmw0Q23UJWtQxquNVTsylbFfdVkWxFhRC06FlWGTVjtvSp79oLQUoPMqyiBZloFTJdTeL0UpUVloPQ5jyHdFU9T7Uiy5z6D0aMOmrXRLnNsxmQtF16nDVieUrT/Of/ah/8nVs/wD+lWDnlp7SrC8nWjTP/wAck/5FWl5NsivCfo4n5zVpSVG1SxIkusRgkcyrGxItl0NYWAWzg4dWUtBXaUQm517CCKsm02IEd5iSFIcSsmorLgsi031C4O4ODVieS43uO49ZcSfJcL4UShCQLjXizZfsOduvFmyvYc7deLNlew5268WbK9hzt14s2V7DnbrxZsr2HO3XizZXsOduvFmyvYc7dW5Z8GGWWYyFl5dQPBmU/cuQcSj96hQY8FrFMJIFWitDcCUpYvAaVVhRgxZzHtuJC1bsvNn9mqrLzFn49+5ZvSzdrwlQ2CSpIKFdaCU1vZ30S3fkk1vNKukddc/Aq4vkKQhCEhKEhI6hwrZ8ly9nVjeS4ez4BIAJJ4hWNed6O5CPQoi8msB7WFfIVgPawr5CsB7WFfIVgPawr5CsB7WFfIVgPawr5CsB7WFfIVgPawr5CsB7WFfIVgPawv5CsB7WFfIVgPawr5CsB7WFfIVgPawr5CsB7WFfIVgPawr5CsB7WFfIVgPawr5CsB7WFfIVdITyO4X4KH8U09jLwRgrHKn1N4ReSJH6KgZhE2Dfdwmv+rtV99EAgg1iWdGj5biUITzUge6hGjheGGWwrrwRfSkJWkpUkEH0EU2000Lm20oH+0XUEJBJCQCawE4WFgjC6/TQQhJJCQL6CEJBASADy3CsW3glOAm7quotoIAKEkDk4qUhCuckH3iltNOXYbaVXcl4vrARhYWCL+u7jrFt4eHgJwuu7jpbDDhCltIUespBopSRgkC7qoAAXAADcj9O/wDlR9SmOyl1TwbTjFcqvTuyYMWX06Cv9RFMR2YyMBpNyb+S8nv3ZebP7NVWXmLPx79yzelm7X6+2fJcvZ1Y3kuHs+BJ+lim/QtXH7h5s79BbTg5QoA+5X1xkX3htOF+PIK/rK5XLvwSKwFaVz51/WHI7f8AgoUHynpU3f7hxigQQCD5n4ReSJH6KgZhE2Dfdwmv+rtV9/m0fOH/AMqPMJebP7NVWXmLPx79yzelm7X6+2fJcvZ1Y3kuHs+A/wBOx+vzZ/mD86O/6wkAEnkFEl7jN4R6B1+/hDCaOEjm+lP8UlQWkKSbwfMvCLyRI/RUDMImwb7uE1/1dqvv82j9O/8AlR5hLzV/Zqqy8xZ+PfuWb0s3a/X2z5Ll7OrG8lw9nwH+nY/X5tI5g/Ojv+seOMcxf+lPGr+PqEHFu3f6V/srzLwi8kSP0VAzCJsG+7hI+i48g8uGVfBXm0XjW8v0EhI/T5hLzZ/Zqqy8xZ+PfuWb0s3a/X2z5LmbOrG8lw9nwH+nY/XwFrS2hS1qASkEkmleEQUpW9obrqBVnWnHnoUW70rTyoP1MKfHnIWtkm5JuN44b/MH50d/1ZIAJNNcaMI8qjhH41MVKQypccowkpJuUkm+mp8l6z23UKaL7qrkJCaYEkJ/rrbKv9iSB+5PBcTeg3cvKPeKQrDQlXWAfMfCLyRI/RUDMIewb7uE8zjLlJNyxyH/AINYbqeJbK/08YrGnQu9msadC72axp0LvZrGnQu9msadC72axp0LvZrGnQu9msadC72axp0LvZrGnQu9msadC72axp0LvZrGnQu9msadC72axp0LvZrGnQu9msadC72axp0LvZrGnQu9mgh93iwS2n0k86kIShISkXAeYS82f2aqsvMWfj37lm9LN2v19s+S5ezqzrfs+PBYZcUvDQivGay/bc7FeM1l+252K8ZrL9tzsUxa0OfKaQwVEpCibxwPCJak2YsD0rSDUJaIVisuttFf0AopTykqqBOhKmvrTBWy9i1rWSaEwysc9JtJxlz/AEISFUbSlPWGtRdWHW3gnDBqUxOZgMTzPdKyEcVWnab5bgNY4tB1lC3Viok7e1osNsTVvsOEJIXSEz5tpTozctaEBaqtLCRJQ1ItLFMobAuQSVmrIeflKmRBLdxeDehZ54qwr2IsuZjF3NDo/QahwZtpR1y1znErJOAKRaUl6w5JLqg60tAw6saNNXipj8oqCmrgjgT3FNRlrSgrKSkhI5TWXpn2O/WX5H2TIrxiX9mSK8ZBqEivGZrUpFeNEbVZFeNMLQP141Wdon68abN9l6vGizP/AC9mleEVnOpKEFy9XEL00BcAKeeQy2Vq9wA5ST6BVko3taEqO4gJUQHG/wAAdyFIekpU4pCQ0ejNLVgtqUCOJJN55KiPLfjMurSEqWgKuG7fb96hHSwWgSE31f4UexGq/wAKPYjVf4UexGq/wo9iNV/hR7Ear/Cj2I1X+FHsRqv8KPYjVf4UexGq/wAKPYjVYk+VMEoSMDCacCeF4ReSJH6KgZhD2Dfd6sl5s/s1VZeYs/Hv3LN6Wbtfr7Z8ly9nVkMMKsyIS0gkt9Vb2j6Fvsit7R9C32RW9o+hb7IpxppD7BQ2lPO5BdwJkVEuM4wvkWKYY8IYCSwyhtxv0GoFkzGp635KgsONKCz+Kqag2xADrMZlp1tRvCzUizp7tlFlaw4+XAqpsGQ9Y7MZABdSlupVkyi1AeYwcew0lJSaitWw9KQ5IS2w0nlQkA31Z8CSxaU59xICHScGn4NoM2q7LYYbfC/bPJVmQJ0e0JL74SQ6k3qTVmWbOYEmI+2je7oN6waZjW9BaXFYbbW2Sbl1kV9qx3o6blPuLBNQGlsQ47SxcpDYB4EjmD86e/6i4VgI9kfKsU1o0fKno7JaXc0i/BPoFIN6UnrApMN/fKH3ZRWEX3IwAAL6kWe49MblJklCkC5NyKmkIgvlYCrmjTjAYjQmQAhsrSHj7k+mrzve0Q22oF13ASLrrgq5FFDiGpIQhW+WkKbCx7PFx1DaZQslCgo4AF6U3J//ANO5GFzCPxvPz+r8HektPb8Lwi8kSP0VAzCJsG+71ZLzZ/Zqqy8xZ+PfuWb0s3a/X2z5Ll7OrG8lw9nwH+nY/X5s/wAwfnR3/WNjBwm/ZP7ejdfiNyFNlal3IPNB4le/gu34OCOVRuFAAAAcgF31fg70lp7fheEXkiR+ioGYRNg33erJebP7NVWXmLPx79yzelm7X6+2fJcvZ1Y3kuHs+A/07H6/NpHMH50d/wBY+gghxI4wLiOsUCFAEG8HhE3Ak0ykrVjTycif5+s8HektPb8Lwi8kSP0VAzCJsG+71ZLzV/Zqqy8xZ+PfuWb0s3a/X2z5Ll7OrG8lw9nwH+nY/X5s/wAwfnT3/WraUglTYvB5U/xSVpVyH3j0jgKWlIvJpLanSCsXI9CfSff9b4O9Jae34XhF5IkfoqBmETYN93qyXmz+zVVl5iz8e/cs3pZu14ZfZHK4mt8se3SVoVzVA+48K2fJcvZ1Y3kuJs+BJSSlK0i9SDfdSVJWkKSbwfNT/VeSgciCFKPcPrltNucahx9dYhwc13tC+sXI62/3rEunnOgflFIZbQbwLz1njP11nQJMt6cWZq2Al83hNZDtH7ZfrIdo/bL9ZDtH7ZfrIdo/bL9ZDtH7ZfpywJrqChy1nVpphrEsMtX34DaUX9dw9WS82f2aqsvMWfj37lm9LN2vBW/xlLYvV6T6BRbwuNxRUf2oBI5ABuFpB9Fx6xxGgt1vrWn9xSFpWkKSbxwLZ8ly9nVjeS4ez4Ko4wiptZQTy3chrFSNMjs1ipOlR2KxUjSo7NYqRpkdmsVJ0qOxWKkaZHZrFSNMjs1ipGmR2axUjSo7NYqRpkdmsVI0yOzWKkaVHZrFSNMjsVipGmR2axUjTI7NYqRpUdmsVI0yOzWKkaZHZrFSdKjsViHlc57si6kNobSEoFw9QeDvSWnt/WcvNn9mqrLzFn49+5ZvSzdrwHnCVYtBu9o9QpKQkAAcI3tqLiP1DrpKgpIUDeCN22fJcvZ1Y3kuHs/XXg70lp7f1nLzZ/Zqqy8xZ+PfuWb0s3a7riwhClH0Cm0kJvPOPGff9QycBxTfoP0k7ts+S5ezqxvJcTZ+uvB3pLT2/rOXmz+zVVl5iz8e/cs3pZu13ZHHi0da+6nHENIUtZuSKjy2pBdCQoKbICkqFxFR5LUlsuNG9OER8uE4Qktr6lfsa3xH0zfaFb4j6ZvtCrXfZVZksB1BJbqyrRgNWdFQ5KaSoI5CqsrWZrjParK9ma4z2qyvZmuNVliy9carLNl643WWbL1xustWVraKy3ZWtorLlla2isuWTraay7ZOtprL1k62Pkay9ZGtDsmsv2RrQ7JrL9ka1+yq8YLI1n9lV4w2RrP/AOFV4w2RrJ7Cq8YrI1g9hVeMdkac9g14x2Tpz2DXjJZOmV2DXjJZOlX2DXjJZWlX2K8ZbK0i+xXjLZXtr7FeM1l+052K8ZrL63OzXjPZfW72a8Z7M/8AL2a8aLM6nuzXjRZnU92a8abN9l7s1402b7D9eNNm6N+vGqztG/XjVZ2ifrxqgaGRXjTB0EivGmHq8ivGiJq0ivGeNqsivGdjVJFeMzOpyK8ZWtSkV4yo1CRXjIjUJFeMqdQkV4yp1CRXjKnUJFeMqdQkV4yp1CRXjKnUJFeMqdQkV4yp1CRXjKnUJFeMqdQkV4N4ZE5ZQU4b1/rOXmz+zVVl5iz8e/cs3pZu13X+lZ/VTiELT9NN4BCviKiPhmyJc1RuceUs1AbMWzWBgEkN3kD8as3AxS57wWhSkqJUo8RSTSJqFOtNFtxKnElSLxygUl5pu0ZzxBOAhKLk9pRrfrZxYQhalrbC8AAXhJ9Jvpl1LzSXE33KFSUBbKknkVcPnXizZfsuduvFmy/Zc7deLNl+y526TYNlBIG9gayHZOqIrIdlaoisiWVqiKyLZWqIrI1l6m3WRrL1Nusj2XqbVZIszU2qyTZmps9msk2ZqbPZrJVm6mz2KyXZupsdgVkuzdSY7ArJlnamx2BWTbO1NjsCsnWfqbHYFZOgamx2BWT4GpsdgVvCDqjHYFbxhaqz2BW8oWqs9gVvKHqzPYFbzias12BW9IurtdgVvWNoGuyK3tG0DfZFb3j6FvsisQxokdkViGdEjsisSzo0fKsU3o0/KsW37CflWAj2E/KsBPsisFPUKuH3Jl5s/s1VZeYs/Hv3LN6Wbtd2RxYtfUvvqWZAjOmOAXcH6INLgb8xKTGDYvCn3CnBKj1JFWjIQ1GeQFDGqaIQn9qkQiuzkRUf6QgdisTLVOD5SlKcWEct5AvvNNwZLRQ+kJxxeWt0BXOB5BW81iS48tpDxcQgcfoKabCghIVdf+HJS+NTaetYPy++MvNn9mqrLzFn49+5ZvSzdruuIC0KSfSKbUSm484G47imWlrStSElSeaSOMcJkYbinPQPop85bftC03XjGfDEZCykLwQtS6iuWixMEWUcc2tF6Hgj9jT1qWew6WnZKErpyVHaS2pbqAFm5JJ4jUe0YMlwtsvoWqn7RgsO4p2QhC+ommJsh6Etwym0ESygKIHNoWs1lRUPDRcEfHGezUR/+3ccelNrCXFXrHEABUe04EleLZkIUunrRgsFYdkISUEAimpUd5nHNupLftU1alnPOBpuSgrpqS8q1pEckYtLKVAbtozX0PMRIoBkPek8iE083bcRGPEsScHjU0W63y0mMl904tBQCcPiuvqNPhy7ww+hZFOWrZzXPlIHGRWPYLOOxqcVdfh38VR7RhSllDEhC1dVLtCEheAp9AVhhF3pwqftOBHcxbshCV1aVqtQ4zTqFtqLhGDW+0mS2tMtvEFgrwPSf91IfZWzjkuAt3E4XouFLnQ0MJfW+gNq5FVHlxpSSph1KwOW7cyvIyqNTx2I/XTzzTDZcdWEIHKTTlqtuy4CIr6VoWtYcpl9mQ2HGlhaOsVv6JiMfj0Yr26jTYku/EPJXdSbQhLcQ2mQgrWSAmsq2djcVvpvDvuqTMixQC+8lF/JfTMyK+0p1p5CkJ5SKdtCMtp1LEtsOYorB5QBRmMR4zTkh9ABQPp+1UebFlJUWHkruqx5L0qA088b1kqq1rTlwpzAbF7Qbw3E1ak1bVlrlRl+wUn3mn5ceM2FvupQDQnw1x1vofQW0cpqzrYYlR2VOuIQ6pWCUUZDAfDGMTjSnCwfTdQkxyXhjU/0uk4+bTFpwJLmLZkIUunbQhMlaXX0JKCAR76hS3HHbQDqxgMvlI/BNMvsvthxpYUg8hHqGXmz+zVVl5iz8e/cs3pZu14DzagrGIF5/wBQ6xSVBQBB4RvcUW0fqPVSUpSkJAuAHnBrwdUEw1xj0rLqgsU9PCZiYbaMNwtqWT7FWG1HXZQUtKVFwrLxNNID0CyW3Be2ZxA/JU9ttu1bIKEBJKnBViNMvR5S3kJU6t9YdvpIQLGuRzMo8VISnxid4hmY/wDahcYDCF9Eu1LnKtxDaG4Sm0gOiS2G6gstLtm1lqQCpJaAoLjsRbaS42S1vq4ISbqtBM1LULHMxmkCQ2EJReV0x5fl/wCMipe/cWN6YrGX8eMvuuqLvvFf3WKxl56O+66n1Bnwhjrc4kuxi2k1aiH2m35QtBbKUo4kACn3ZMlFh34CyvCUQ5zVLFFmXlSC48IjS71C5BN601YsdhSZ61NpJVLdFXryTAaFxQZpBCuSpLEwyYC3RDZKX0hBQTeas1hldo2q6tAKw8ACajrdeEtyHFYQyt1eG4+SSqhd4tRduP8A3p1Iy9HTcLt6KorcYiybIT0hkhtvZuVJaeTbEZhltohqIMUl2ojT6bYK3N7IUpj6bbRNWjKESE+/6Up+j7zSoVp5JDG9EaXDw/pX09JROXYZd6JwqK/zipzTCLYspSEpDhK6deNnZUho5XSFsDa1LjOMSbHiNpbWEIUQHOYV0lmVleI49vVpeCsFLZN6xVjMRxEmPLACi87eusU/Fs7AWwxLggX4SCULupx4Pz2d6RUuPCMDhuqICEKqLjRKtwOYrDxAvDXN5KZYZb8G1rS2AtcckqpTgUqymmoyXZCYoWkrVchIqFjxbkkP4kLMTjDVeD3kpj3rqQEqt+MCLwYq6tK+BFl2csktLIXHP6uNNSN8rtxIbQysojAoDtRWXhaclTu9klcb6bTZPaptm/waZdR0jK8aP0LovXzMrgnFiUGv0FNxpwE2Yy65xIlzwt38hq3W20RoxbQA6l9AauqOwy7btpLcQFFCWrqkplF20lgXxES73kA3FVR1MrYaUzdiykYF3V6hl5s/s1VZeYs/Hv3LN6WbteCtjjKmzgq9PUaLhT0iSnuoKSeQg7hdQPTeeocZoIdc/wBif3NIQlCQlIuHnKysIUUAFVxuBNwJqVZ0qU7jjDaQ57bb5SahxZsIKxMFi9XOWXiSacsqSta1CIhAWb1oRIISqlR5qhHG8GAGFhTYDx/inW7QedYdXDYK2SSg44/xT1mynnlu7zQgr6QIkFIXQgSQxiBAYDeNxlwfPLTsac7KbkmGyHUekPkUIcoRnIxgMFtaiogvGmLOlsOod3qhxaOZjJBUE003aDTz7yIbAW7cVnHH+KMKUpElBgMFL6sJd75rJD5RcuIlfUpUlRKabZntvl5MNnGFsIJL55BWOtbVGP8A7j/FY61tUY/+4/xUpmdMaxb8GOpO2NN2TISoFcRDt3IHJBUBS4ctcVEYwWMWjmf1jeKiwpsZ0uiI2t267DcfKjUdu0IwcDUNgBays3vHlNCFKEVUUwGC0STcXjTFnzGHUu71Q4tPNLkgquplu0GVvOIhsAuqwl/1j/FZKkFxat5thK1XqbEhQQaFnSRGcjbyaxK133F803GnNutOiI0VttlCSX1HioxpipiJZgMY5IuBxxqZGnS8DGQ2QtHNWl8hQqJFnRCstw2StfOWt8qUaktT5aEIehsFKVhfTH+Kxtraox/9p/isnP72MbeDOLKyvpzek0zZspp1t7eiFuo5FrkEmno0199l9yCwXGuYccalsTpiAh6ExxG9JDxBBqLDmxXC6mI2twi4rW+VGmGp8dtTbcJjBUokgvE8tZIkaqMVot8qwKkwZkhxDpiNoWlODe2+U01Z0llZU3BaThIKFAPqoMThE3pvJjFYGB0x/in4Ex4MXxG0FlAShaHyFAUzZ0lh5DzcJoLSNYV9KoyLQispZahsBA63j/FFq0FSUSTDYxqEFAOOP8VMjTZyAh+CwQDpiKlxZsvFlcNoLRzVofKVCokabEC8XDZKl89anyVGo8OZGbeabhM4DnKkvqNCDKEIw94MYnbmlszlxRGXAjlrACQnHGmLNlsuod3qhwo5mMkFQRSG7QbfefTDYw3bsM472aaantF8phMf1lFS73j/ABURq0IjWKZhshG3JpsrKElxISu7jAN4B9QSs2f2aqsvMWfj37lm9LN2vDLDKuVtNb2Y0YpKEJ5qQPcPvpLzZ/Zqqy8xZ+PfuWb0s3a/f2Xmz+zVVl5iz8e/cs3pZu1+/svNn9mqrLzFn49+5ZvSzdr9/ZebP7NVWXmLPx79yzelm7X7+y82f2aqsvMWfj37lm9LN2v39l5s/s1VZeYs/Hv3GJzcV6UFpUcJ08lZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXWWmNGustMaNdZaY0a6y0xo11lpjRrrLTGjXT1rMOMuIDa71JIqy8xZ+Pfuf/EACYRAAMAAAQGAwEBAQAAAAAAAAABERAgMVACMEBBUZESYGFwgYD/2gAIAQIBAT8A/jbcKysT877rkT3vzlWv0Bb41SYJZkiEIQh8SEIT9+gvdrynvUxmCH9AfVpd2RERERERERERERDUz1Hy/GJ3oX1a0XL4u2Zu5E7lpWVlZWVlZWVlZX56xaLBspSlKUWHH2yvuIeK12taLCEIQhCY8fbKxZFrta0XL4u2ZqZEptaZ6PR6PR6PR6PR6KvKG7n+KPj+sSn/AB9Sou+t5E79AWq+gLVb41kS31pEEt9bxThrvbyrXe3hOgj8EZGRkZGRkZGRk2R5VrzFy3o9laxSolOZw9+W9Hs8XOXLej6ThR/iPR6PR6PR6PR6PRxKZ/kfL8E0+bw9+W9H0i0XL4u2Zu5E7zFy3o+kWiwZSlKUosOLKxDxWv8AnNv4UpSlKUpRu9ItFhCEIQhMeLtlYsi12taLl8XbM1kSmxtwrK/wTuVMq8lXkq8lXkq8lXkq8lXkq8lQ3c7SPihKbQnd74tMvDq97aqYsLhw93vjWFErv0/CL++f/8QAKxEAAwABAgUCBgIDAAAAAAAAAAERAjFQECAwUYFAQQMSITJgYXBxE0KA/9oACAEDAQE/AP4bWLYsMUfLj2Rlh231KJIq4/EWj3vH7l/YxasqKZ/Z53xOpPhCHxHot8xy+UTT0Z5Ms0tOeEIQhCEIT8Bf4A9/Q/wB+rbKyvuV9yvuV9yvuV9yvuV9ysTvPUUvoX6t69PHmb5E7zUpSlKUpS+sevGEIQhOOPO+K12t68KUpSlLxx6S12t69PHma5EptbXTSnPEQn/HyTeiP8eXZDTWq33DG8f0zPGb4lEl+iuzjkri981S/omjp9T6mX2vfMMvZ8meV+i33HPIebX+jMs299xwv1ZppweKY0097xVyXLmrjvfw/u8DEyiY9H/XVhCEIQhCE2XFzJcIQhm5j1F03suOfs/D4tpasbbfUW4pte582T931l0+/pGzyeTyeTyeTyeTzwT56X9Cd6q9e9enjzN8id6i6ff0j14whCEJxx9+ZD4rXq0pSlKUpS+levClKUpS8cektdrevTx5muRKbG3ClYneVojIyMjIyMjIyMjEpzxEW0p3e3pyre3yrfGuKV3+fz5//9k=)\n",
    "\n",
    "In this project, all latent vectors $z$ are sampled from a multivariate standard normal distribution in `dim_latent_space`, i.e. drawn from $N(0,I_{\\text{dim_latent_space}})$.\n",
    "\n",
    "Also, it is hard for a network to work directly with categorical data such as labels. Therefore, the label should be encoded in some way before being given to the CGAN. The most common and naive way to do this is to use is to use \"one-hot encoding\". The idea is to create a vector with one 1 for the class it belongs to and 0 for every other class. However, this might not be really efficient computationwise and memorywise.  The solution is to let the model find by itself an Embedding vector for each label, in an embedding space with a chosen dimension. This embedding space is continuous and learnable, which improves the encoding of the labels. In practice, the embedding is done using the `torch.nn.Embedding` layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6af844",
   "metadata": {
    "id": "cf6af844"
   },
   "source": [
    "### Information about architectures ###\n",
    "The `getInfoModel` function uses the `torchinfo` package in order to deliver as many useful information about your model as possible. It allows you for example to know the total number of parameters in your model, or to see how many parameters compose each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc09d526",
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1727106035726,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "fc09d526"
   },
   "outputs": [],
   "source": [
    "##### Infos about a model\n",
    "\n",
    "def getInfoModel(model, batch_size, model_name=None):\n",
    "    if isinstance(model.input_size, list):\n",
    "        input_size = [(batch_size, ) + in_size for in_size in model.input_size]\n",
    "        dtypes = [in_type for in_type in model.input_type]\n",
    "    else:\n",
    "        input_size = (batch_size, ) + model.input_size\n",
    "        dtypes = model.input_type\n",
    "    print(input_size)\n",
    "    model_summary = summary(model, input_size=input_size, dtypes=dtypes, verbose=0,\n",
    "                            col_names=[\"input_size\",\"output_size\",\"num_params\",\"kernel_size\"])\n",
    "    if model_name != None:\n",
    "        print(\"Model: \" + model_name)\n",
    "    print(model_summary)\n",
    "    return model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fbbbd0",
   "metadata": {
    "id": "c4fbbbd0"
   },
   "source": [
    "### Architectures\n",
    "You receive a basic / reference *Generator* and *Discriminator* architectures. You can change these neural network architectures if you want: you can add or remove layers, you can change their width, yo can modify the kernels, you can add connections, you can change the type of layers, you can change the activation functions, ... Whatever you like the most!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2abc41",
   "metadata": {
    "id": "0d2abc41"
   },
   "source": [
    "### 1.1a Discriminator class\n",
    "\n",
    "The Discriminitor takes a batch of 1x28x28 pixels images and a batch of labels associated with the images as input, and ouputs numbers between -inf and +inf (`forward()`). The activation of the last layer represents some likelihood of the image being real or not, according to the model. Afterwards, it goes through a sigmoid function in order to scale numbers between 0 and 1 (`scalingOutputs()`) such that they look like probabilities. An output of 0.0 means that the model is certain that the corresponding input image is fake, and an output of 1.0 means that it is certain input is real.\n",
    "\n",
    "Notice that the `forward(x,y)` function of the discriminator, which is called when doing a \"forward pass\" through the discriminator, receives two inputs: an image $x$ and label indication $y$. Most of the time, $y$ will be an integer (i.e. the label), but we also allow it to be a floating point label embedding vector. This will be useful for interpolation between labels later in the homework.\n",
    "\n",
    "The function `embeddingToLabel()` performs a 1-NN (nearest neighbour) classification for embedding vectors which do not correspond directly to a label.\n",
    "\n",
    "You cannot change any method definition (nor its name nor its arguments) and all methods should be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6846a97",
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1727106035726,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "b6846a97"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_label_encoding, classes, ndf, image_resize, threshold=0.5):\n",
    "        self.dim_label_encoding = dim_label_encoding\n",
    "        self.classes = classes\n",
    "        self.n_classes = len(self.classes)\n",
    "        self.ndf = ndf      # Depth of feature maps in the first layer of the discriminator\n",
    "        self.n_channels = image_resize[0]\n",
    "        self.height = image_resize[1]\n",
    "        self.width = image_resize[2]\n",
    "        self.input_size = [image_resize, ()]      # empty/contracted dimension (because only one element per datapoint)\n",
    "        self.input_type = [torch.float, torch.int]\n",
    "        self.output_size = ()\n",
    "        self.output_type = torch.float\n",
    "        self.threshold = threshold\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if self.height%4 != 0 or self.width%4 != 0:\n",
    "            print(\"Dimension problems coming\")\n",
    "\n",
    "        self.emb0 = nn.Embedding(self.n_classes, self.dim_label_encoding)\n",
    "        self.lin0 = nn.Linear(self.dim_label_encoding, 1*self.height*self.width)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(self.n_channels+1, self.ndf, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.lrelu1 = nn.LeakyReLU(0.2)\n",
    "        self.drop1 = nn.Dropout2d(0.25)\n",
    "        self.conv2 = nn.Conv2d(self.ndf, self.ndf*2, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.lrelu2 = nn.LeakyReLU(0.2)\n",
    "        self.drop2 = nn.Dropout2d(0.25)\n",
    "        self.conv3 = nn.Conv2d(self.ndf*2, self.ndf*4, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.lrelu3 = nn.LeakyReLU(0.2)\n",
    "        self.drop3 = nn.Dropout2d(0.25)\n",
    "        self.conv4 = nn.Conv2d(self.ndf*4, self.ndf*4, kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.lrelu4 = nn.LeakyReLU(0.2)\n",
    "        self.drop4 = nn.Dropout2d(0.25)\n",
    "        self.lin5 = nn.Linear((self.ndf*4)*(self.height//4)*(self.width//4), 1)\n",
    "\n",
    "    def scalingOutputs(self, x):\n",
    "        scaled_outputs = torch.sigmoid(x)\n",
    "        return scaled_outputs\n",
    "\n",
    "    def predict(self, x, threshold=None):\n",
    "        if threshold == None:\n",
    "            threshold = self.threshold\n",
    "        x_scaled = self.scalingOutputs(x)\n",
    "        x_predicted = torch.where(x_scaled > threshold, 1.0, 0.0)\n",
    "        return x_predicted\n",
    "\n",
    "    def labelToEmbedding(self, label):\n",
    "        emb = self.emb0(label)\n",
    "        return emb\n",
    "\n",
    "    def embeddingToLabel(self, emb, device):\n",
    "        emb_classes = self.emb0(generateLabelVectors(self.n_classes, self.n_classes, label_type=\"range\", device=device))\n",
    "        labels = torch.argmin(torch.cdist(emb, emb_classes), axis=1)\n",
    "        return labels\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        if y.dtype in [torch.int, torch.int32, torch.int64]:   # y is a label\n",
    "            emb = self.labelToEmbedding(y)\n",
    "        else:    # y is an embedding\n",
    "            emb = y\n",
    "        emb = self.lin0(emb)\n",
    "        emb = emb.view(-1, 1, self.height, self.width)\n",
    "\n",
    "        x = torch.cat([x, emb], 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.lrelu1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.lrelu2(x)\n",
    "        x = self.drop2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.lrelu3(x)\n",
    "        x = self.drop3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.lrelu4(x)\n",
    "        x = self.drop4(x)\n",
    "        x = x.view(-1, (self.ndf*4)*(self.height//4)*(self.width//4))\n",
    "        x = self.lin5(x)\n",
    "        x = x.view(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae52ab24",
   "metadata": {
    "id": "ae52ab24"
   },
   "source": [
    "### 1.1b Generator class\n",
    "The Generator class takes a batch of latent vectors and a batch of labels as inputs. Indeed, the generator will create an image (1x28x28) from each input latent vector (1 color i.e. gray-scale, 28x28 pixels) and each desired label. The latents vectors are of dimension dim_latent_space with each entry sampled from a standard normal distribution $N(0,1)$.\n",
    "\n",
    "The latent space is thus a space where the information contained in the images is compressed/condensed. This latent space will be the focus of the second part of the homework.\n",
    "\n",
    "Similarly to the discriminator, the generator `forward(z,y)` function receives a latent vector $z$ and a $y$ which can be either an integer label or floating point label embedding vector (in which case you skip the embedding module).\n",
    "\n",
    "The function `embeddingToLabel()` performs a 1-NN (nearest neighbour) classification for embedding vectors which do not correspond directly to a label.\n",
    "\n",
    "You cannot change any method definition (nor its name nor its arguments) and all methods should be completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba51efd8",
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1727106035727,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "ba51efd8"
   },
   "outputs": [],
   "source": [
    "##### Define a class for a Generator neural network\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_latent_space, dim_label_encoding, classes, ngf, image_resize):\n",
    "        self.dim_latent_space = dim_latent_space\n",
    "        self.dim_label_encoding = dim_label_encoding\n",
    "        self.classes = classes\n",
    "        self.n_classes = len(self.classes)\n",
    "        self.ngf = ngf      # Depth of feature maps in the last layer of the generator\n",
    "        self.n_channels = image_resize[0]\n",
    "        self.height = image_resize[1]\n",
    "        self.width = image_resize[2]\n",
    "        self.input_size = [(self.dim_latent_space, ), ()]    # empty dimension\n",
    "        self.input_type = [torch.float, torch.int]\n",
    "        self.output_size = image_resize\n",
    "        self.output_type = torch.float\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if self.height%4 != 0 or self.width%4 != 0:\n",
    "            print(\"Dimension problems coming\")\n",
    "\n",
    "        self.emb0 = nn.Embedding(self.n_classes, self.dim_label_encoding)\n",
    "\n",
    "        self.lin1 = nn.Linear(self.dim_latent_space+self.dim_label_encoding, (self.ngf*4)*(self.height//4)*(self.width//4))\n",
    "        self.batch_norm1 = nn.BatchNorm2d(self.ngf*4)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.trans_conv2 = nn.ConvTranspose2d(self.ngf*4, self.ngf*4, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(self.ngf*4)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.trans_conv3 = nn.ConvTranspose2d(self.ngf*4, self.ngf*2, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(self.ngf*2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.trans_conv4 = nn.ConvTranspose2d(self.ngf*2, self.ngf, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.batch_norm4 = nn.BatchNorm2d(self.ngf)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.trans_conv5 = nn.ConvTranspose2d(self.ngf, self.n_channels, kernel_size = 3, stride = 2, padding = 1, output_padding = 1)\n",
    "        self.tanh5 = nn.Tanh()\n",
    "\n",
    "    def labelToEmbedding(self, label):\n",
    "        emb = self.emb0(label)\n",
    "        return emb\n",
    "\n",
    "    def embeddingToLabel(self, emb, device):\n",
    "        emb_classes = self.emb0(generateLabelVectors(self.n_classes, self.n_classes, label_type=\"range\", device=device))\n",
    "        labels = torch.argmin(torch.cdist(emb, emb_classes), axis=1)\n",
    "        return labels\n",
    "\n",
    "    def forward(self, z, y, device=None):\n",
    "        batch_size = len(z)\n",
    "        x = z.clone()\n",
    "\n",
    "        if y.dtype in [torch.int, torch.int32, torch.int64] and device == None:    # y is a label, device not precised\n",
    "            labels = y.clone()\n",
    "            emb = self.labelToEmbedding(labels)\n",
    "        elif device != None:     # y is an embedding, device precised\n",
    "            emb = y.clone()\n",
    "            labels = self.embeddingToLabel(emb, device)\n",
    "\n",
    "        names = [self.classes[label] for label in labels.tolist()]\n",
    "        emb = emb.view(-1, self.dim_label_encoding)\n",
    "\n",
    "        x = torch.cat([x, emb], 1)\n",
    "        x = self.lin1(x)\n",
    "        x = x.view(-1, self.ngf*4, self.height//4, self.width//4)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.trans_conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.trans_conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.trans_conv4(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.trans_conv5(x)\n",
    "        x = self.tanh5(x)\n",
    "\n",
    "        dict_image = {'image': x, 'latent_vector': z, 'label_embedding': emb, 'number': labels, 'name': names, 'generated': [True]*batch_size}\n",
    "        return dict_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a7ae37",
   "metadata": {
    "id": "46a7ae37"
   },
   "source": [
    "Here are some important parameters for the definition the reference architecture. First of all, the dimension of the label embedding space. Then, the dimension of the latent space for the generator. Finally, the depths of the features of the first (resp. last) layer of the Discriminator (resp. Generator), which basically dictate the size of the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0ce03",
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1727106035728,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "d7e0ce03"
   },
   "outputs": [],
   "source": [
    "##### Define your GAN model (Discriminator+Generator)\n",
    "\n",
    "dim_label_encoding = dataset.n_classes//3\n",
    "ndf = 32\n",
    "dim_latent_space = 50\n",
    "ngf = 16\n",
    "\n",
    "discriminator = Discriminator(dim_label_encoding, dataset.classes, ndf, image_resize).to(device)\n",
    "generator = Generator(dim_latent_space, dim_label_encoding, dataset.classes, ngf, image_resize).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36aecba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1727106035728,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "c36aecba",
    "outputId": "9bf3a720-1164-49b3-c727-e68a73053c7f"
   },
   "outputs": [],
   "source": [
    "##### Information about the models\n",
    "\n",
    "discriminator_info = getInfoModel(discriminator, batch_size, model_name = \"discriminator\")\n",
    "generator_info = getInfoModel(generator, batch_size, model_name = \"generator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67be1ba",
   "metadata": {
    "id": "f67be1ba"
   },
   "source": [
    "### Loss functions\n",
    "\n",
    "The loss function measures how good the model is. For the discriminator, it a binary classification problem: the discriminator tries to distinguish true data (label = 1) from fake generated ones (label = 0). Therefore, we use a Binary Cross Entropy loss. As the only goal of the generator is to fool the discriminator, it can also be expressed with a Binary Cross Entropy loss function. The generator wins when the discriminator classified generated data as true (label = 1) and and true data as faked (label = 0)\n",
    "\n",
    "You see that `BCELoss` is replaced by `BCEWithLogitsLoss` for training stability issues. This implies that the output of the discriminator forward pass is not scaled to `[0.0,1.0]`, i.e. there is no sigmoid scaling last layer of any Discriminator architecture.\n",
    "\n",
    "This loss function should **not** be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54134141",
   "metadata": {
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1727106035728,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "54134141"
   },
   "outputs": [],
   "source": [
    "# Loss function for the GAN\n",
    "\n",
    "#loss_function = torch.nn.BCELoss()\n",
    "loss_function = torch.nn.BCEWithLogitsLoss()     # DON'T MODIFY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32307abd",
   "metadata": {
    "id": "32307abd"
   },
   "source": [
    "Let's also enable printing of the loss at a given epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eb7b3f",
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1727106035729,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "04eb7b3f"
   },
   "outputs": [],
   "source": [
    "def printGANLoss(loss_discriminator, loss_generator, epoch):\n",
    "    print(\"Epoch %d: Mean Loss Discriminator: %.3f\" %(epoch, np.mean(loss_discriminator[epoch])))\n",
    "    print(\"Epoch %d: Mean Loss Generator: %.3f\" %(epoch, np.mean(loss_generator[epoch])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f292027",
   "metadata": {
    "id": "8f292027"
   },
   "source": [
    "### Optimizers\n",
    "In machine learning and neural networks training in particular, adaptive stochastic gradient descent algorithm are used and have seen an impressive amount of development over the last 10 years. For your information, those types of optimization algorithms are variants on the famous gradient descent (first order algorithms). On the one hand, the stochasticity (randomness) comes from the fact that we compute the gradient only on one batch at a time, which is a random selection of few data points within the whole dataset. This randomness allows for more robustness against local minima, which is a positive side effect of using batches for training. On the other hand, the adaptivity means that the stepsize is adapted at each iteration using acceleration techniques, giving faster convergence.\n",
    "\n",
    "Within those algorithms, Adam is the most famous and massively used one. You can play around with the Adam parameters if you want.\n",
    "\n",
    "You are free to try other algorithms for training, for example AdamW which is a variant of Adam compatible with weight decay ($L_2$ regularization), another popular technique to improve the quality of results in learning problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6657fa6",
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1727106035729,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "d6657fa6"
   },
   "outputs": [],
   "source": [
    "##### Optimizers\n",
    "\n",
    "lr_discriminator = 0.0002\n",
    "betas_discriminator = (0.5, 0.999)\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr_discriminator, betas=betas_discriminator)\n",
    "\n",
    "lr_generator = 0.0002\n",
    "betas_generator = (0.5, 0.999)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr_generator, betas=betas_generator)\n",
    "\n",
    "# weight_decay_discriminator = 0.01\n",
    "# optimizer_discriminator = torch.optim.AdamW(discriminator.parameters(), lr=lr_discriminator, betas=betas_discriminator, weight_decay=weight_decay_discriminator)\n",
    "# optimizer_generator = torch.optim.AdamW(generator.parameters(), lr=lr_generator, betas=betas_generator, weight_decay=weight_decay_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1575b128",
   "metadata": {
    "id": "1575b128"
   },
   "source": [
    "### Metrics: accuracy (of the discriminator) and timing\n",
    "    \n",
    "We define one error measure as the accuracy reached by the discriminator for its predictions `y_predicted`, i.e. the ratio between the number of correct classifications and the total number of samples.\n",
    "\n",
    "During the training, data are loaded batch by batch. It could thus be a good idea to consider that the inputs of the following function are the true and predicted labels from one batch of data. The following method also compute the accuracy of you model on the true data and on the generated/fake data separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45b5e03",
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1727106035729,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "a45b5e03"
   },
   "outputs": [],
   "source": [
    "def computeGANAccuracy(y_predicted, y_official, threshold=0.5):\n",
    "    y_predicted = y_predicted.cpu().detach().numpy()\n",
    "    y_official = y_official.cpu().detach().numpy()\n",
    "    ind_real = np.argwhere(y_official==1)\n",
    "    ind_fake = np.argwhere(y_official==0)\n",
    "    accuracy = accuracy_score(y_official, y_predicted)\n",
    "    accuracy_real = accuracy_score(y_official[ind_real], y_predicted[ind_real])\n",
    "    accuracy_fake = accuracy_score(y_official[ind_fake], y_predicted[ind_fake])\n",
    "    return [accuracy,accuracy_real,accuracy_fake]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50127951",
   "metadata": {
    "id": "50127951"
   },
   "source": [
    "Let's also enable printing of the loss at a given epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dac44",
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1727106035730,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "8f5dac44"
   },
   "outputs": [],
   "source": [
    "def printGANAccuracy(accuracy_train, accuracy_test, epoch):\n",
    "    print(\"Epoch %d: Mean Discriminator Training Accuracy: %.3f (global), %.3f (real), %.3f (fake)\" %(epoch, np.mean(accuracy_train[epoch,:,0]),np.mean(accuracy_train[epoch,:,1]),np.mean(accuracy_train[epoch,:,2])))\n",
    "    print(\"Epoch %d: Mean Discriminator Testing Accuracy: %.3f (global), %.3f (real), %.3f (fake)\" %(epoch, np.mean(accuracy_test[epoch,:,0]),np.mean(accuracy_test[epoch,:,1]),np.mean(accuracy_test[epoch,:,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaba820",
   "metadata": {
    "id": "afaba820"
   },
   "source": [
    "Another widely used metrics is the training time. Timing is done in the training process below with the famous `time` package. Here is a simple function to help you print your timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99295caa",
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1727106035730,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "99295caa"
   },
   "outputs": [],
   "source": [
    "def computeAndPrintTime(title, epoch, start_time, end_time):\n",
    "    delta_time = end_time - start_time\n",
    "    hours = delta_time // 3600\n",
    "    minutes = (delta_time - hours*3600) // 60\n",
    "    seconds = delta_time - hours*3600 - minutes*60\n",
    "    print(title, \"%d: %d h %d min %.1f sec\" %(epoch, hours, minutes, seconds))\n",
    "    return delta_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dd7569",
   "metadata": {
    "id": "a9dd7569"
   },
   "source": [
    "### Create data to feed the networks\n",
    "\n",
    "As we are in Conditional GAN settings, both networks require labels corresponding to the classes of the images we would like to generate or to discriminate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59d56c3",
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1727106035731,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "e59d56c3"
   },
   "outputs": [],
   "source": [
    "def generateLabelVectors(n_vectors, n_classes, labels=None, label_type=\"range\", device=\"cpu\"):\n",
    "    if isinstance(labels, list) and label_type == \"given\":\n",
    "        labels = torch.tensor(labels)\n",
    "    elif isinstance(labels, int) and label_type == \"same\":\n",
    "        labels = torch.ones((n_vectors,), dtype=torch.int)*labels\n",
    "    elif labels == None and label_type == \"range\":\n",
    "        labels = torch.arange(n_vectors) % n_classes\n",
    "    elif labels == None and label_type == \"random\":\n",
    "        labels = torch.randint(n_classes, (n_vectors,))\n",
    "    else:\n",
    "        print(\"Undefined label_type\")\n",
    "    labels = labels.to(device)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9327b8",
   "metadata": {
    "id": "3d9327b8"
   },
   "source": [
    "All latent vectors $z$ are sampled from a multivariate standard normal distribution in `dim_latent_space`, i.e. drawn from $N(0,I_{\\text{dim_latent_space}})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f332819",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1727106035731,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "9f332819"
   },
   "outputs": [],
   "source": [
    "def generateLatentVectors(n_vectors, dim_latent_space, scaling=1.0, device=\"cpu\"):\n",
    "    z = torch.randn((n_vectors, dim_latent_space)).to(device)*scaling\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4383ba07",
   "metadata": {
    "id": "4383ba07"
   },
   "source": [
    "For their training, both your generator and your discriminator need to receive inputs that they can handle. These inputs can either be extracted for the dataset (for the discriminator), either created (for the generator and for the discriminator).\n",
    "\n",
    "While training the discriminator, fake/generated images are labelled as 0 and true images as 1, to work with the usual BCE loss for classification. On the contrary, while training the generator, fake/generated images are labelled as 1 and true images as 0, so that the generator wins when the discriminator fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451a37e",
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1727106035731,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "d451a37e"
   },
   "outputs": [],
   "source": [
    "def createGeneratorData(batch_size, dim_latent_space, n_classes, device, labels=None, label_type=\"random\", training='generator'):\n",
    "    latent_space_samples = generateLatentVectors(batch_size, dim_latent_space, device=device)\n",
    "    generated_samples_numbers = generateLabelVectors(batch_size, n_classes, labels=labels, label_type=\"random\", device=device)\n",
    "\n",
    "    if training == 'generator':\n",
    "        # Generator tries to fool discriminator: all generated samples are fake (0), but generator wins when discriminator thinks it's real (1)\n",
    "        generated_samples_labels = torch.ones((batch_size, )).to(device)   # Fake/generated labels are 1\n",
    "    elif training == 'discriminator':\n",
    "        # Discriminator tries distinguish all fake generated samples (0) from real data (1)\n",
    "        generated_samples_labels = torch.zeros((batch_size, )).to(device)   # Fake/generated labels are 0\n",
    "\n",
    "    return latent_space_samples, generated_samples_numbers, generated_samples_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31ca98",
   "metadata": {
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1727106035731,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "9a31ca98"
   },
   "outputs": [],
   "source": [
    "def createDiscriminatorData(data, generator, dim_latent_space, device, shuffle = False):\n",
    "    real_samples = data['image']\n",
    "    real_samples_numbers = data['number']\n",
    "    batch_size = real_samples.__len__()\n",
    "\n",
    "    real_samples = real_samples.to(device)\n",
    "    real_samples_labels = torch.ones((batch_size, )).to(device)         # Real labels are 1\n",
    "    real_samples_numbers = real_samples_numbers.to(device)\n",
    "\n",
    "    latent_space_samples, generated_samples_numbers, generated_samples_labels = createGeneratorData(batch_size, dim_latent_space, generator.n_classes, device, training='discriminator')\n",
    "    generated_samples = generator(latent_space_samples, generated_samples_numbers)\n",
    "\n",
    "    all_samples = torch.cat((real_samples, generated_samples['image']))\n",
    "    all_samples_labels = torch.cat((real_samples_labels, generated_samples_labels))\n",
    "    all_samples_numbers = torch.cat((real_samples_numbers, generated_samples_numbers))\n",
    "\n",
    "    if shuffle:\n",
    "        perm = torch.randperm(batch_size*2)\n",
    "        all_samples = all_samples[perm]\n",
    "        all_samples_labels = all_samples_labels[perm]\n",
    "        all_samples_numbers = all_samples_numbers[perm]\n",
    "\n",
    "    return all_samples, all_samples_labels, all_samples_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d208d55",
   "metadata": {
    "id": "7d208d55"
   },
   "source": [
    "### Preparing the training process\n",
    "In this part, you are asked to initialize the training process (not the model which is initialized automatically).\n",
    "\n",
    "Let's just first define the number of iterations (epochs) that the training will last. Satisfactory results can be obtained with 10 epochs, but you can of course increase this value for a longer training.\n",
    "    \n",
    "It turns out in practice that the generator is often harder to train than the discriminator. Therefore, we propose you another parameter which allows to train the generator on more batches than the discriminator: the discriminator will only see a proportion of 1/generator_advantage of the batches. Note that the parameter has to be greater or equal to 1. Sometimes, the discriminator could be harder to train, therefore we also define a discriminator_advantage parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2fee98",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1727106035731,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "4d2fee98"
   },
   "outputs": [],
   "source": [
    "##### Training parameters\n",
    "\n",
    "num_epochs = 15\n",
    "generator_advantage = 1.0       # >= 1.0\n",
    "discriminator_advantage = 1.0   # >= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45aca15",
   "metadata": {
    "id": "c45aca15"
   },
   "source": [
    "It is important to keep track of the evolution of the error metrics during the training process. A simple idea is to store the values of the metrics in arrays, at least after every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c986f",
   "metadata": {
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1727106035732,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "020c986f"
   },
   "outputs": [],
   "source": [
    "loss_discriminator = np.zeros((num_epochs+1, n_batches_train))\n",
    "loss_generator = np.zeros((num_epochs+1, n_batches_train))\n",
    "accuracy_train = np.zeros((num_epochs+1, n_batches_train, 3))\n",
    "accuracy_test = np.zeros((num_epochs+1, n_batches_test, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf405618",
   "metadata": {
    "id": "bf405618"
   },
   "source": [
    "It is a good option to keep track of the evolution of the images generated through the training. Defining a reference sample of latent vectors allows to generate the image for the same inputs every time. You can compute the output from those vectors after each epoch to see how the generated images evolve with the training. The latent vectors are generated from a standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec13df1c",
   "metadata": {
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1727106035732,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "ec13df1c"
   },
   "outputs": [],
   "source": [
    "# Reference latent vectors\n",
    "\n",
    "reference_latent_space_samples = generateLatentVectors(batch_size, dim_latent_space, device=device)\n",
    "reference_number_samples = generateLabelVectors(batch_size, dataset.n_classes, label_type=\"range\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b0de6",
   "metadata": {
    "id": "ad8b0de6"
   },
   "source": [
    "### Evaluation at initialization\n",
    "\n",
    "We want to determine the performances of the model before the training. Now, to measure how (badly) our model performs at initialization by computing the loss of the generator, the loss of the discriminator and the accuracy of the discriminator. We can also visually assess the quality of the image generated by the generator by showing the images for the reference latent vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff67d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 733
    },
    "executionInfo": {
     "elapsed": 38225,
     "status": "ok",
     "timestamp": 1727106073913,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "9aff67d8",
    "outputId": "fda24166-988e-429a-ec3a-1ffa932fd235"
   },
   "outputs": [],
   "source": [
    "##### Initial values of loss and accuracy\n",
    "\n",
    "epoch = 0\n",
    "print(\"EPOCH\", epoch)\n",
    "\n",
    "discriminator.eval()\n",
    "generator.eval()\n",
    "\n",
    "for batch, data in enumerate(train_loader):\n",
    "    all_samples, all_samples_labels, all_samples_numbers = createDiscriminatorData(data, generator, dim_latent_space, device)\n",
    "    output_discriminator = discriminator(all_samples, all_samples_numbers)\n",
    "    loss_discriminator[epoch,batch] = loss_function(output_discriminator, all_samples_labels)\n",
    "    predictions = discriminator.predict(output_discriminator)\n",
    "    accuracy_train[epoch, batch] = computeGANAccuracy(predictions, all_samples_labels)\n",
    "\n",
    "    latent_space_samples, generated_samples_numbers, generated_samples_labels = createGeneratorData(batch_size, dim_latent_space, generator.n_classes, device, training='generator')\n",
    "    generated_samples = generator(latent_space_samples, generated_samples_numbers)\n",
    "    output_discriminator_generated = discriminator(generated_samples['image'], generated_samples_numbers)\n",
    "    loss_generator[epoch,batch] = loss_function(output_discriminator_generated, generated_samples_labels)\n",
    "\n",
    "for batch, data in enumerate(test_loader):\n",
    "    all_samples, all_samples_labels, all_samples_numbers = createDiscriminatorData(data, generator, dim_latent_space, device)\n",
    "    output_discriminator = discriminator(all_samples, all_samples_numbers)\n",
    "    predictions = discriminator.predict(output_discriminator)\n",
    "    accuracy_test[epoch, batch] = computeGANAccuracy(predictions, all_samples_labels)\n",
    "\n",
    "printGANLoss(loss_discriminator, loss_generator, epoch)\n",
    "printGANAccuracy(accuracy_train, accuracy_test, epoch)\n",
    "\n",
    "##### Show reference sample\n",
    "generated_samples = generator(reference_latent_space_samples, reference_number_samples)\n",
    "plotSamples(generated_samples, epoch=epoch, source=source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47378b",
   "metadata": {
    "id": "cc47378b"
   },
   "source": [
    "### 1.b Training and testing the GAN\n",
    "\n",
    "This is finally the core part of this section: training your CGAN.\n",
    "\n",
    "The training will follow an easy structure. Here is the basic pseudo-code of the training process of a GAN:\n",
    "\n",
    "```\n",
    "    for each epoch:\n",
    "\n",
    "        for each batch:\n",
    "\n",
    "            train the discriminator on the batch:\n",
    "\n",
    "                generate fake data\n",
    "\n",
    "                predict if data from the batch and generated data are fake or not\n",
    "\n",
    "                compute the discriminator loss function\n",
    "\n",
    "                backpropagate the error in the discriminator\n",
    "\n",
    "            train the generator on the batch:\n",
    "\n",
    "                generate fake data\n",
    "\n",
    "                predict if generated data are fake or not\n",
    "\n",
    "                compute the generator loss function\n",
    "\n",
    "                backpropagate the error in the generator\n",
    "\n",
    "        end\n",
    "\n",
    "    end\n",
    "```\n",
    "    \n",
    "Several improvements are already proposed in the implementation below, such as best \"top-k training\" [Sinha et al, 2020] and changing the schedule of number of generator and discriminator updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47506d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 660615,
     "status": "ok",
     "timestamp": 1727106734507,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "3e47506d",
    "outputId": "63903cd9-0be4-4624-e5b8-9ee36e2ef023"
   },
   "outputs": [],
   "source": [
    "##### Training of the GAN\n",
    "\n",
    "time_start = time.time()\n",
    "n_seen_data = 0\n",
    "print(\"Training starts\")\n",
    "\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    time_start_epoch = time.time()\n",
    "    print(\"EPOCH\", epoch)\n",
    "\n",
    "    disc_tot = 0\n",
    "    gen_tot = 0\n",
    "\n",
    "    for batch, data in enumerate(train_loader):\n",
    "\n",
    "        discriminator.train()\n",
    "        generator.eval()\n",
    "\n",
    "        # Data for training the discriminator (2*batch_size in total: batch_size true + batch_size fake)\n",
    "        all_samples, all_samples_labels, all_samples_numbers = createDiscriminatorData(data, generator, dim_latent_space, device)\n",
    "\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        output_discriminator = discriminator(all_samples, all_samples_numbers)\n",
    "        loss_d = loss_function(output_discriminator, all_samples_labels)\n",
    "        loss_discriminator[epoch,batch] = loss_d\n",
    "        predictions = discriminator.predict(output_discriminator)\n",
    "        accuracy_train[epoch, batch] = computeGANAccuracy(predictions, all_samples_labels)\n",
    "\n",
    "        # Don't train discriminator at each batch: train the discriminator every generator_advantage batch\n",
    "        if torch.rand(1)*max(generator_advantage,1.0) < 1.0:\n",
    "            loss_d.backward()\n",
    "            optimizer_discriminator.step()\n",
    "            disc_tot += 1\n",
    "\n",
    "        discriminator.eval()\n",
    "        generator.train()\n",
    "\n",
    "        # Data (from latent space) for training the generator (2*batch_size in total: batch_size*2 fake)\n",
    "        latent_space_samples, generated_samples_numbers, generated_samples_labels = createGeneratorData(batch_size*2, dim_latent_space, generator.n_classes, device, training='generator')\n",
    "\n",
    "        # Training the generator\n",
    "        generator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples, generated_samples_numbers)\n",
    "        output_discriminator_generated = discriminator(generated_samples['image'], generated_samples_numbers)\n",
    "        # Top-k training: we train the generator only with its k best generated samples (we choose k=batch_size//3)\n",
    "        k_output_discriminator_generated, k_indices = torch.topk(output_discriminator_generated, k, dim=0, sorted=False)\n",
    "        loss_g = loss_function(k_output_discriminator_generated, generated_samples_labels[k_indices])\n",
    "        loss_generator[epoch,batch] = loss_g\n",
    "\n",
    "        if torch.rand(1)*max(discriminator_advantage,1.0) < 1.0:\n",
    "            loss_g.backward()\n",
    "            optimizer_generator.step()\n",
    "            gen_tot += 1\n",
    "\n",
    "        n_seen_data += len(data)\n",
    "\n",
    "    # Show loss training\n",
    "    printGANLoss(loss_discriminator, loss_generator, epoch)\n",
    "\n",
    "    discriminator.eval()\n",
    "    generator.eval()\n",
    "\n",
    "    # Compute accuracy on test set\n",
    "    for batch, data in enumerate(test_loader):\n",
    "\n",
    "        all_samples, all_samples_labels, all_samples_numbers = createDiscriminatorData(data, generator, dim_latent_space, device)\n",
    "        output_discriminator = discriminator(all_samples, all_samples_numbers)\n",
    "        predictions = discriminator.predict(output_discriminator)\n",
    "        accuracy_test[epoch, batch] = computeGANAccuracy(predictions, all_samples_labels)\n",
    "\n",
    "    # Show accuracy (train + test sets)\n",
    "    printGANAccuracy(accuracy_train, accuracy_test, epoch)\n",
    "\n",
    "    # Check generated images\n",
    "    if epoch % max(1,(num_epochs//15)) == 0:\n",
    "        generated_samples = generator(reference_latent_space_samples, reference_number_samples)\n",
    "        plotSamples(generated_samples, epoch=epoch, source=source)\n",
    "\n",
    "    time_end_epoch = time.time()\n",
    "    time_epoch = computeAndPrintTime(\"Time epoch\", epoch, time_start_epoch, time_end_epoch)\n",
    "\n",
    "time_end = time.time()\n",
    "time_training = computeAndPrintTime(\"Total training time epochs\", epoch, time_start, time_end)\n",
    "mean_time_epoch = time_training/num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df0fd3-45c4-441c-bfe7-796c02bd350e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d976ce8a-bcdf-4857-bfa4-0309569263f3",
   "metadata": {
    "id": "7fdf8295"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Cargar el modelo del Discriminador\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m discriminator \u001b[38;5;241m=\u001b[39m \u001b[43mDiscriminator\u001b[49m(dim_label_encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, ndf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))  \u001b[38;5;66;03m# Define con los mismos valores que usaste durante el entrenamiento\u001b[39;00m\n\u001b[1;32m      5\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/julia/Escritorio/ERASMUS/Algoritmica/hw1/Discriminator__2024_10_09__17_52_18\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Cambia la ruta al archivo de tu modelo guardado\u001b[39;00m\n\u001b[1;32m      6\u001b[0m discriminator\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# Pon el discriminador en modo de evaluación\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Cargar el modelo del Discriminador\n",
    "discriminator = Discriminator(dim_label_encoding=10, ndf=32, image_size=(1, 28, 28))  # Define con los mismos valores que usaste durante el entrenamiento\n",
    "discriminator.load_state_dict(torch.load('/home/julia/Escritorio/ERASMUS/Algoritmica/hw1/Discriminator__2024_10_09__17_52_18'))  # Cambia la ruta al archivo de tu modelo guardado\n",
    "discriminator.eval()  # Pon el discriminador en modo de evaluación\n",
    "\n",
    "# Cargar el modelo del Generador\n",
    "generator = Generator(dim_latent_space=50, dim_label_encoding=10, ngf=16, image_size=(1, 28, 28))  # Define con los mismos valores que usaste durante el entrenamiento\n",
    "generator.load_state_dict(torch.load('/home/julia/Escritorio/ERASMUS/Algoritmica/hw1/Generator__2024_10_09__17_52_18'))  # Cambia la ruta al archivo de tu modelo guardado\n",
    "generator.eval()  # Pon el generador en modo de evaluación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3cb82a",
   "metadata": {
    "id": "dd3cb82a"
   },
   "source": [
    "### Plot the results\n",
    "You should plot the evolution of your error metrics (accuracy and loss function) in function of the number of epochs, to see how efficient the training is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ede77e2-50c2-4ee2-8218-a3d9f3a36ca8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Crear un vector latente aleatorio y una etiqueta para generar un dígito (por ejemplo, 3)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Crear un vector latente aleatorio y una etiqueta para generar un dígito (por ejemplo, 3)\n",
    "latent_vector = torch.randn(1, 50)  # Vector latente con dimensión 50 (ejemplo)\n",
    "label = torch.tensor([3])  # Generar un dígito '3'\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_image = generator(latent_vector, label)\n",
    "\n",
    "# Mostrar la imagen generada\n",
    "plt.imshow(generated_image.squeeze(), cmap='gray')\n",
    "plt.title(f'Generated Image for label {label.item()}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3e7be",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1727106734507,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "1af3e7be"
   },
   "outputs": [],
   "source": [
    "def plotGANLoss(loss_discriminator_stats, loss_generator_stats, num_epochs, source=\".\"):\n",
    "    plt.close(\"Loss\")\n",
    "    plt.figure(\"Loss\", figsize = (20,15))\n",
    "    plt.title(\"Loss during training\", fontsize=30)\n",
    "    plt.grid()\n",
    "    epochs = np.arange(num_epochs+1)\n",
    "    plt.plot(epochs, loss_discriminator_stats[0], label = \"Discriminator\")\n",
    "    plt.fill_between(epochs, loss_discriminator_stats[0]-loss_discriminator_stats[1], loss_discriminator_stats[0]+loss_discriminator_stats[1], alpha = 0.3)\n",
    "    plt.plot(epochs, loss_generator_stats[0], label = \"Generator\")\n",
    "    plt.fill_between(epochs, loss_generator_stats[0]-loss_generator_stats[1], loss_generator_stats[0]+loss_generator_stats[1], alpha = 0.3)\n",
    "    plt.legend(fontsize=30)\n",
    "    plt.xlabel(\"Epochs\", fontsize=30)\n",
    "    plt.ylabel(\"Loss\", fontsize=30)\n",
    "    plt.ylim(bottom=0.0)\n",
    "    plt.tick_params(axis = 'both', which = 'both',labelsize = 30)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    now = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "    plt.savefig(source + '/Figures/Loss__' + now + '__' + str(num_epochs) + '_epochs.png')\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plotGANAccuracy(accuracy_train_stats, accuracy_test_stats, num_epochs, source=\".\"):\n",
    "    plt.close(\"Accuracy\")\n",
    "    plt.figure(\"Accuracy\", figsize = (20,15))\n",
    "    plt.title(\"Accuracy of discriminator\", fontsize=30)\n",
    "    plt.grid()\n",
    "    colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "    epochs = np.arange(num_epochs+1)\n",
    "    plt.plot(epochs, accuracy_train_stats[0][:,0], label = \"Train\", color=colors[0], linestyle='-')\n",
    "    plt.fill_between(epochs, accuracy_train_stats[0][:,0]-accuracy_train_stats[1][:,0], accuracy_train_stats[0][:,0]+accuracy_train_stats[1][:,0], alpha = 0.3, color=colors[0])\n",
    "    plt.plot(epochs, accuracy_train_stats[0][:,1], label = \"Train real\", color=colors[0], linestyle='--')\n",
    "    plt.plot(epochs, accuracy_train_stats[0][:,2], label = \"Train fake\", color=colors[0], linestyle=':')\n",
    "    plt.plot(epochs, accuracy_test_stats[0][:,0], label = \"Test\", color=colors[1], linestyle='-')\n",
    "    plt.fill_between(epochs, accuracy_test_stats[0][:,0]-accuracy_test_stats[1][:,0], accuracy_test_stats[0][:,0]+accuracy_test_stats[1][:,0], alpha = 0.3, color=colors[1])\n",
    "    plt.plot(epochs, accuracy_test_stats[0][:,1], label = \"Test real\", color=colors[1], linestyle='--')\n",
    "    plt.plot(epochs, accuracy_test_stats[0][:,2], label = \"Test fake\", color=colors[1], linestyle=':')\n",
    "    plt.legend(fontsize=30)\n",
    "    plt.xlabel(\"Epochs\", fontsize=30)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=30)\n",
    "    plt.ylim(0.0,1.0)\n",
    "    plt.axhline(y=0.5, color='darkgray', linestyle='--', label='Random classifier')\n",
    "    plt.tick_params(axis = 'both', which = 'both',labelsize = 30)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    now = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "    plt.savefig(source + '/Figures/Accuracy__' + now + '__' + str(num_epochs) + '_epochs.png')\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a8ee81-52dd-4841-89ea-b34b3ee19520",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torchinfo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorchinfo\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torchinfo' is not defined"
     ]
    }
   ],
   "source": [
    "torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41035af6",
   "metadata": {
    "id": "41035af6"
   },
   "source": [
    "### 1.c Error metrics for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b55c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2413,
     "status": "ok",
     "timestamp": 1727106736911,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "c95b55c8",
    "outputId": "314ce690-1336-4206-a199-c7c1ec6b8efc"
   },
   "outputs": [],
   "source": [
    "loss_discriminator_stats = (np.mean(loss_discriminator, axis = 1), np.std(loss_discriminator, axis = 1))\n",
    "loss_generator_stats = (np.mean(loss_generator, axis = 1), np.std(loss_generator, axis = 1))\n",
    "accuracy_train_stats = (np.mean(accuracy_train, axis = 1), np.std(accuracy_train, axis = 1))\n",
    "accuracy_test_stats = (np.mean(accuracy_test, axis = 1), np.std(accuracy_test, axis = 1))\n",
    "\n",
    "plotGANLoss(loss_discriminator_stats, loss_generator_stats, num_epochs, source=source)\n",
    "plotGANAccuracy(accuracy_train_stats, accuracy_test_stats, num_epochs, source=source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dcd3d5",
   "metadata": {
    "id": "53dcd3d5"
   },
   "source": [
    "### Save your models\n",
    "A really useful feature for your experiments is to be able to save your models. This can be done with the torch.save function. In the function saveModel, a model is stored in the folder ./Models that you may want to create (or any other folder if defined otherwise above). The (date)time is used to always store your models with a different name and never lose some training that you would have done.\n",
    "\n",
    "Be careful however: the saveModel function below stores the \"state dictionary\" of your model, not your model itself.\n",
    "\n",
    "You can of course modify the function saveModel as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf88b6c",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1727106736912,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "bbf88b6c"
   },
   "outputs": [],
   "source": [
    "def saveModel(model, model_name, source='.'):\n",
    "    now = datetime.now().strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "    torch.save(model.state_dict(), source + '/Models/' + model_name + '__' + now)\n",
    "\n",
    "#### Example\n",
    "#\n",
    "# D = Discriminator().to(device)\n",
    "# saveModel(D, \"Discriminator\")\n",
    "#\n",
    "##\n",
    "# The model D has been saved as \"Discriminator__2022_11_12__15_21\" in the folder Models as your code finished running at\n",
    "# 15:21 on the 12 November 2022.\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92d4b5b",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1727106736912,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "b92d4b5b"
   },
   "outputs": [],
   "source": [
    "##### Save discriminator and generator\n",
    "\n",
    "saveModel(discriminator, 'Discriminator', source=source)\n",
    "saveModel(generator, 'Generator', source=source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb92cfab",
   "metadata": {
    "id": "bb92cfab"
   },
   "source": [
    "### Load your models\n",
    "You can also load models that you trained and saved earlier with the function loadModel.\n",
    "\n",
    "However, be careful. You will have to first recreate a new instance of your class, and then import the state dictionary in the new instance. This means that the characteristics of your class should not have changed since then. In particular, the number of layers and the size of the layers need to match between the trained model and the most recent class in order to correctly assign the stored parameters. Moreover, there could be some trouble if you changed functions/methods from the class.\n",
    "\n",
    "You can of course modify the function loadModel as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036fb4d",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1727106736912,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "d036fb4d"
   },
   "outputs": [],
   "source": [
    "def loadModel(model, model_name, date_time, device=\"cpu\", source='.'):\n",
    "    model.load_state_dict(torch.load(source + '/Models/' + model_name + '__' + date_time, map_location=device))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "#### Example\n",
    "#\n",
    "# D = Discriminator().to(device)\n",
    "# loadModel(D, \"Discriminator\", \"2022_11_12__15_21\")\n",
    "#\n",
    "##\n",
    "# The model \"Discriminator__2022_11_12__15_21\" from the folder Models has been loaded in the Discriminator D\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d414f70-5c05-43a3-bd75-a15e3eb93c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Asegúrate de que las arquitecturas del Discriminador y Generador están definidas previamente\n",
    "\n",
    "# Cargar el modelo del Discriminador\n",
    "discriminator = Discriminator()  # Debes haber definido previamente la clase Discriminator en tu notebook\n",
    "discriminator.load_state_dict(torch.load('/home/julia/Escritorio/ERASMUS/Algoritmica/hw1/Discriminator__2024_10_09__17_52_18'))  # Cambia la ruta al archivo de tu modelo guardado\n",
    "discriminator.eval()  # Pon el discriminador en modo de evaluación\n",
    "\n",
    "# Cargar el modelo del Generador\n",
    "generator = Generator()  # Debes haber definido previamente la clase Generator en tu notebook\n",
    "generator.load_state_dict(torch.load('/home/julia/Escritorio/ERASMUS/Algoritmica/hw1/Generator__2024_10_09__17_52_18'))  # Cambia la ruta al archivo de tu modelo guardado\n",
    "generator.eval()  # Pon el generador en modo de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1fd5ca-7704-47f3-8950-b3c76c874644",
   "metadata": {
    "id": "7fdf8295"
   },
   "outputs": [],
   "source": [
    "## Section 2: Analyse your CGAN\n",
    "\n",
    "You made it half-way through! This second part is dedicated to the analysis of some features of your trained GAN. Let's first load a particular save of your neural networks. Change the name of the file to load the models you want (i.e. change the datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283fd259-b764-44cb-816b-e2eff6a08c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0cc9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "executionInfo": {
     "elapsed": 1062,
     "status": "error",
     "timestamp": 1727106761425,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "10f0cc9c",
    "outputId": "1c18ae15-5a3f-4437-8f89-c6be27f0a44f"
   },
   "outputs": [],
   "source": [
    "##### Load discriminator and generator\n",
    "\n",
    "discriminator = Discriminator(dim_label_encoding, dataset.classes, ndf, image_resize).to(device)\n",
    "generator = Generator(dim_latent_space, dim_label_encoding, dataset.classes, ngf, image_resize).to(device)\n",
    "\n",
    "name=None     # TO COMPLETE\n",
    "loadModel(discriminator, 'Discriminator', name, source=source, device=device)\n",
    "loadModel(generator, 'Generator', name, source=source, device=device)\n",
    "\n",
    "discriminator_info = getInfoModel(discriminator, batch_size, model_name = \"discriminator\")\n",
    "generator_info = getInfoModel(generator, batch_size, model_name = \"generator\")\n",
    "\n",
    "# Make sure that your model is fixed for testing\n",
    "\n",
    "discriminator.eval()\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19edcf5c",
   "metadata": {
    "id": "19edcf5c"
   },
   "source": [
    "You have now to analyze your latent space by yourself. To help you, don't hesitate to use every method that you defined in your Discriminator and Generator as well as all the other functions given in the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac1a0f",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1727106736912,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "86ac1a0f"
   },
   "outputs": [],
   "source": [
    "# Show one representative of each class\n",
    "\n",
    "latent_space_samples = generateLatentVectors(dataset.n_classes, dim_latent_space, device=device)\n",
    "all_samples_numbers = generateLabelVectors(dataset.n_classes, dataset.n_classes, label_type=\"range\", device=device)\n",
    "emb = generator.labelToEmbedding(all_samples_numbers)\n",
    "generated_samples_bis = generator(latent_space_samples, emb, device)\n",
    "plotSamples(generated_samples_bis, epoch=None, source=source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec955d3",
   "metadata": {
    "id": "2ec955d3"
   },
   "source": [
    "### 2.1 Diversity in each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15308b79",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1727106736912,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "15308b79"
   },
   "outputs": [],
   "source": [
    "# Diversity in one class\n",
    "\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bf395f",
   "metadata": {
    "id": "77bf395f"
   },
   "source": [
    "### 2.2 Discrimination in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1dd51d",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1727106736913,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "5e1dd51d"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (4221257523.py, line 50)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 50\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"Class {class_label}: Accuracy: {accuracy:.4f}, Fake/Real %: {fake_real_count:.4f}, False Positives:\u001b[0m\n\u001b[0m                                                                                                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def discriminationPerClass(generator, discriminator, dataset, n_samples_per_class=500, batch_size=64, device=\"cpu\"):\n",
    "\n",
    "\n",
    "    n_classes = dataset.n_classes # Number of classes\n",
    "    accuracy_per_class = []\n",
    "    fake_real_percentages = []\n",
    "    false_positives = []\n",
    "    false_negatives = []\n",
    "    # Loop over each class\n",
    "    for class_label in range(n_classes):\n",
    "    # Step 1: Generate fake images for the class\n",
    "        latent_space_samples = generateLatentVectors(n_samples_per_class, dim_latent_space, device=device)\n",
    "        label_vector = torch.ones(n_samples_per_class, dtype=torch.long).to(device) * class_label\n",
    "        emb = generator.labelToEmbedding(label_vector)\n",
    "        generated_samples = generator(latent_space_samples, emb, device)['image']\n",
    "    # Step 2: Extract real samples from the dataset\n",
    "    real_samples = []\n",
    "    count = 0\n",
    "    for sample in dataset:\n",
    "        if sample['number'] == class_label:\n",
    "            real_samples.append(sample['image'].unsqueeze(0)) # Add image to the list\n",
    "            count += 1\n",
    "        if count == n_samples_per_class: # Stop after n_samples_per_class\n",
    "            break\n",
    "    real_samples = torch.cat(real_samples).to(device) # Convert list to tensor\n",
    "    \n",
    "    # Step 3: Combine fake and real samples\n",
    "    all_samples = torch.cat([real_samples, generated_samples])\n",
    "    all_labels = torch.cat([torch.ones(n_samples_per_class), torch.zeros(n_samples_per_class)]).to(device)\n",
    "\n",
    "    # Step 4: Run samples through discriminator\n",
    "    all_predictions = discriminator(all_samples, label_vector.repeat(2))\n",
    "    \n",
    "    # Step 5: Convert discriminator outputs to binary predictions (fake/real)\n",
    "    predictions = discriminator.predict(all_predictions)\n",
    "    \n",
    "    # Step 6: Calculate accuracy for the class\n",
    "    accuracy = accuracy_score(all_labels.cpu(), predictions.cpu())\n",
    "    accuracy_per_class.append(accuracy)\n",
    "\n",
    "    # Step 7: Calculate Fake/Real percentages\n",
    "    fake_real_count = torch.sum(predictions).item() / len(predictions)\n",
    "    fake_real_percentages.append(fake_real_count)\n",
    "    \n",
    "    # Step 8: Calculate false positives and false negatives\n",
    "    false_pos = torch.sum((predictions == 1) & (all_labels == 0)).item() / n_samples_per_class\n",
    "    false_neg = torch.sum((predictions == 0) & (all_labels == 1)).item() / n_samples_per_class\n",
    "    false_positives.append(false_pos)\n",
    "    false_negatives.append(false_neg)# Step 9: Print class-level stats\n",
    "    print(f\"Class {class_label}: Accuracy: {accuracy:.4f}, Fake/Real %: {fake_real_count:.4f}, False Positives:\n",
    "    {false_pos:.4f}, False Negatives: {false_neg:.4f}\")\n",
    "    \n",
    "    # Return the computed metrics for further analysis or plotting\n",
    "    return accuracy_per_class, fake_real_percentages, false_positives, false_negatives\n",
    "    \n",
    "    # Example usage of the function:\n",
    "    accuracy_per_class, fake_real_percentages, false_positives, false_negatives = discriminationPerClass(\n",
    "    generator, discriminator, train_dataset, n_samples_per_class=500, batch_size=batch_size, device=device)\n",
    "# Now, you can analyze or visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f666f0b",
   "metadata": {
    "id": "0f666f0b"
   },
   "source": [
    "### 2.3 Outside of distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1804fa5e",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1727106736913,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "1804fa5e"
   },
   "outputs": [],
   "source": [
    "# Random embedding vectors\n",
    "\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9eaf65",
   "metadata": {
    "id": "0d9eaf65"
   },
   "source": [
    "### 2.4 Interpolation for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011105c",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1727106736913,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "1011105c"
   },
   "outputs": [],
   "source": [
    "def interpolate(start_tensor, end_tensor, device, n_steps=10):\n",
    "    interpolating_tensor = start_tensor + torch.outer(torch.linspace(0,1,n_steps).to(device), end_tensor-start_tensor)\n",
    "    return interpolating_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e471011",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "aborted",
     "timestamp": 1727106736914,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "7e471011"
   },
   "outputs": [],
   "source": [
    "# Interpolate within a class\n",
    "\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ccfbf",
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "aborted",
     "timestamp": 1727106736914,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "638ccfbf"
   },
   "outputs": [],
   "source": [
    "# Interpolate between two classes\n",
    "\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdcf7fb",
   "metadata": {
    "id": "abdcf7fb"
   },
   "source": [
    "### 2.5 Noise for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cb8939",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1727106736914,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "98cb8939"
   },
   "outputs": [],
   "source": [
    "# Noise on latent vectors\n",
    "\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4940c2e",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1727106736914,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "a4940c2e"
   },
   "outputs": [],
   "source": [
    "# Noise on embedding vectors\n",
    "\n",
    "# TO COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b740ebf",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1727106033251,
     "user": {
      "displayName": "Bastien Massion 2",
      "userId": "07642060934184783175"
     },
     "user_tz": -120
    },
    "id": "5b740ebf"
   },
   "outputs": [],
   "source": [
    "##### Class for EMNISTDataset, child of torchvision.datasets.ImageFolder\n",
    "\n",
    "class EMNISTDataset(ImageFolder):\n",
    "    \"\"\"EMNIST dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root=None, image_resize=(1,28,28), dataset_name=\"MNIST\", interpolation_mode=\"bilinear\", transform_mode=\"normalization\", target_transform_mode=\"basic\", number=None):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.root = root\n",
    "        self.transform = self.getTransform(image_resize, interpolation_mode, transform_mode)\n",
    "        self.target_transform = self.getTargetTransform(target_transform_mode)\n",
    "        self.original_dataset = self.getOriginalDataset()\n",
    "        self.data, self.n_data, self.targets, self.samples, self.classes, self.n_classes, self.class_distribution = self.extractFromEMNIST()\n",
    "        self.augmented_data, self.n_augmented_data = self.augmentData(number=number)\n",
    "\n",
    "\n",
    "    def getTransform(self, image_resize, interpolation_mode, transform_mode):\n",
    "        self.image_size = image_resize\n",
    "        self.interpolation_mode = interpolation_mode\n",
    "        inter_mode = self.getInterpolationMode()\n",
    "        self.transform_mode = transform_mode\n",
    "        n_channels, width, height = self.image_size\n",
    "        if self.transform_mode == 'augmentation':\n",
    "            transform = t.Compose([\n",
    "                                    t.ToTensor(),\n",
    "                                    SwapAxesTransform(),\n",
    "                                    t.Resize((height,width), interpolation=inter_mode, antialias=True),\n",
    "                                    t.RandomHorizontalFlip(),\n",
    "                                    t.RandomRotation((-30,30)),\n",
    "                                    t.RandomCrop((height,width), padding=(height//8,width//8)),\n",
    "                                    t.ColorJitter(brightness=0.5,saturation=0.5),\n",
    "                                    t.Normalize((0.5,), (0.5,))\n",
    "                                  ])\n",
    "        elif transform_mode == 'normalization':\n",
    "            transform = t.Compose([\n",
    "                                    t.ToTensor(),\n",
    "                                    SwapAxesTransform(),\n",
    "                                    t.Resize((height,width), interpolation=inter_mode, antialias=True),\n",
    "                                    t.Normalize((0.5,), (0.5,))\n",
    "                                  ])\n",
    "        else:\n",
    "            print(\"Undefined transform_mode\")\n",
    "        return transform\n",
    "\n",
    "\n",
    "    def getInterpolationMode(self):\n",
    "        if self.interpolation_mode == \"bilinear\":\n",
    "            mode = t.InterpolationMode.BILINEAR\n",
    "        elif self.interpolation_mode == \"bicubic\":\n",
    "            mode = t.InterpolationMode.BICUBIC\n",
    "        elif self.interpolation_mode == \"nearest\":\n",
    "            mode = t.InterpolationMode.NEAREST_EXACT\n",
    "        else:\n",
    "            print(\"Undefined interpolation_mode\")\n",
    "        return mode\n",
    "\n",
    "\n",
    "    def getTargetTransform(self, target_transform_mode):\n",
    "        self.target_transform_mode = target_transform_mode\n",
    "        if target_transform_mode == \"basic\":\n",
    "            if self.dataset_name == \"EMNIST_Letters\":\n",
    "                target_transform = ShiftTargetTransform(-1)\n",
    "            else:\n",
    "                target_transform = None     # No target transform mode defined yet\n",
    "        else:\n",
    "            print(\"Undefined target_transform_mode\")\n",
    "        return target_transform\n",
    "\n",
    "\n",
    "    def getOriginalDataset(self):\n",
    "        if self.dataset_name == \"MNIST\":\n",
    "            return EMNIST(root=self.root, split=\"mnist\", train=True, download=True, transform=self.transform, target_transform=self.target_transform)\n",
    "        elif self.dataset_name == \"EMNIST_Letters\":\n",
    "            return EMNIST(root=self.root, split=\"letters\", train=True, download=True, transform=self.transform, target_transform=self.target_transform)\n",
    "        elif self.dataset_name == \"EMNIST_Balanced\":\n",
    "            return EMNIST(root=self.root, split=\"balanced\", train=True, download=True, transform=self.transform, target_transform=self.target_transform)\n",
    "        else:\n",
    "            print(\"Undefined dataset\")   \n",
    "\n",
    "\n",
    "    def extractFromEMNIST(self):\n",
    "        classes = self.original_dataset.classes.copy()\n",
    "        targets = self.original_dataset.targets.tolist().copy()\n",
    "        if self.dataset_name == \"EMNIST_Letters\":\n",
    "            if \"N/A\" in classes:\n",
    "                classes.remove(\"N/A\")\n",
    "            targets = torch.tensor(targets) - 1\n",
    "            targets = targets.tolist()\n",
    "        samples = targets\n",
    "        n_classes = len(classes)\n",
    "        n_data = len(targets)\n",
    "        data = []\n",
    "        class_distribution = [0]*n_classes\n",
    "        for idx in range(n_data):\n",
    "            target = targets[idx]\n",
    "            name = classes[target]\n",
    "            data += [[target, name]]\n",
    "            class_distribution[target] += 1\n",
    "\n",
    "        return data, n_data, targets, samples, classes, n_classes, class_distribution\n",
    "\n",
    "\n",
    "    def augmentData(self, number=None):\n",
    "        if number != None and type(number) == int:\n",
    "            repeats = max(number//self.n_data,1)\n",
    "            augmented_data = self.data*repeats\n",
    "        else:\n",
    "            augmented_data = self.data\n",
    "        n_augmented_data = len(augmented_data)\n",
    "        return augmented_data, n_augmented_data\n",
    "\n",
    "\n",
    "    def getInfos(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        identity = self.augmented_data[idx]\n",
    "        number = identity[0]\n",
    "        name = identity[1]\n",
    "        return number, name\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # In practice, only one index at a time\n",
    "        image = self.original_dataset.__getitem__(idx)[0]\n",
    "        number = self.original_dataset.__getitem__(idx)[1]\n",
    "        name = self.classes[number]\n",
    "        generated = False\n",
    "\n",
    "        dict_image = {'image': image, 'number': number, 'name': name, 'index': idx, 'generated': generated}\n",
    "        return dict_image"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
